{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 13. Regresi Multiple (Multiple Linear Regression)\n",
        "\n",
        "## Tujuan Pembelajaran\n",
        "- Memahami konsep regresi linear berganda\n",
        "- Membuat model regresi dengan beberapa variabel independen\n",
        "- Menginterpretasikan koefisien regresi\n",
        "- Mengevaluasi kualitas model regresi\n",
        "- Memahami multikolinearitas dan cara mengatasinya\n",
        "- Menerapkan regresi multiple dalam analisis data\n",
        "- Memahami regularisasi dan feature selection\n",
        "\n",
        "## Materi\n",
        "1. Pengertian Regresi Multiple (Multiple Linear Regression)\n",
        "2. Asumsi Regresi Multiple (Multiple Regression Assumptions)\n",
        "3. Interpretasi Koefisien (Coefficient Interpretation)\n",
        "4. Evaluasi Model (Model Evaluation)\n",
        "5. Multikolinearitas (Multicollinearity)\n",
        "6. Feature Selection dan Regularisasi\n",
        "7. Diagnostik Model (Model Diagnostics)\n",
        "8. Aplikasi Praktis Regresi Multiple\n",
        "9. Best Practices dan Troubleshooting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(\"NumPy version:\", np.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Pengertian Regresi Multiple (Multiple Linear Regression)\n",
        "\n",
        "### 1.1 Definisi Regresi Multiple\n",
        "\n",
        "**Regresi Multiple** adalah perluasan dari regresi linear sederhana yang melibatkan dua atau lebih variabel independen untuk memprediksi satu variabel dependen. Metode ini memungkinkan kita untuk memodelkan hubungan linear antara variabel dependen dan beberapa variabel independen secara bersamaan.\n",
        "\n",
        "### 1.2 Model Regresi Multiple\n",
        "\n",
        "#### 1.2.1 Persamaan Regresi\n",
        "```\n",
        "Y = β₀ + β₁X₁ + β₂X₂ + ... + βₖXₖ + ε\n",
        "```\n",
        "\n",
        "Dimana:\n",
        "- **Y**: Variabel dependen (response variable)\n",
        "- **X₁, X₂, ..., Xₖ**: Variabel independen (predictor variables)\n",
        "- **β₀**: Intercept (konstanta)\n",
        "- **β₁, β₂, ..., βₖ**: Koefisien regresi (slopes)\n",
        "- **ε**: Error term (residual)\n",
        "\n",
        "#### 1.2.2 Persamaan Prediksi\n",
        "```\n",
        "Ŷ = b₀ + b₁X₁ + b₂X₂ + ... + bₖXₖ\n",
        "```\n",
        "\n",
        "Dimana:\n",
        "- **Ŷ**: Prediksi nilai Y\n",
        "- **b₀, b₁, b₂, ..., bₖ**: Estimasi parameter β₀, β₁, β₂, ..., βₖ\n",
        "\n",
        "### 1.3 Keunggulan Regresi Multiple\n",
        "\n",
        "1. **Kontrol Confounding**: Mengontrol efek variabel lain\n",
        "2. **Prediksi Lebih Akurat**: Menggunakan informasi dari semua variabel\n",
        "3. **Identifikasi Faktor Penting**: Menentukan variabel mana yang paling berpengaruh\n",
        "4. **Model Komprehensif**: Memodelkan hubungan yang kompleks\n",
        "5. **Efisiensi Statistik**: Lebih powerful daripada analisis terpisah\n",
        "\n",
        "### 1.4 Keterbatasan Regresi Multiple\n",
        "\n",
        "1. **Multikolinearitas**: Korelasi tinggi antar variabel independen\n",
        "2. **Overfitting**: Model terlalu kompleks untuk data\n",
        "3. **Asumsi Kompleks**: Lebih banyak asumsi yang harus dipenuhi\n",
        "4. **Interpretasi Sulit**: Sulit menginterpretasikan koefisien\n",
        "5. **Sample Size**: Membutuhkan sample size yang lebih besar\n",
        "\n",
        "### 1.5 Aplikasi Regresi Multiple\n",
        "\n",
        "1. **Penelitian Medis**: Prediksi risiko penyakit berdasarkan faktor risiko\n",
        "2. **Penelitian Ekonomi**: Model permintaan dengan beberapa variabel\n",
        "3. **Penelitian Psikologi**: Prediksi perilaku berdasarkan faktor psikologis\n",
        "4. **Penelitian Bisnis**: Prediksi penjualan berdasarkan faktor pemasaran\n",
        "5. **Penelitian Pendidikan**: Prediksi prestasi berdasarkan faktor input\n",
        "6. **Penelitian Teknologi**: Prediksi performa sistem berdasarkan parameter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Asumsi Regresi Multiple (Multiple Regression Assumptions)\n",
        "\n",
        "### 2.1 Asumsi Utama\n",
        "\n",
        "#### 2.1.1 Linear Relationship\n",
        "- **Definisi**: Hubungan antara variabel dependen dan independen harus linear\n",
        "- **Pengecekan**: Scatter plot, residual plot\n",
        "- **Solusi**: Transformasi data, polynomial regression\n",
        "\n",
        "#### 2.1.2 Independence\n",
        "- **Definisi**: Observasi harus independen satu sama lain\n",
        "- **Pengecekan**: Durbin-Watson test, residual plot\n",
        "- **Solusi**: Time series models, mixed-effects models\n",
        "\n",
        "#### 2.1.3 Normality\n",
        "- **Definisi**: Residuals harus berdistribusi normal\n",
        "- **Pengecekan**: Q-Q plot, Shapiro-Wilk test\n",
        "- **Solusi**: Transformasi data, robust regression\n",
        "\n",
        "#### 2.1.4 Homoscedasticity\n",
        "- **Definisi**: Varian residuals harus konstan\n",
        "- **Pengecekan**: Residual plot, Breusch-Pagan test\n",
        "- **Solusi**: Transformasi data, weighted regression\n",
        "\n",
        "#### 2.1.5 No Multicollinearity\n",
        "- **Definisi**: Tidak ada korelasi tinggi antar variabel independen\n",
        "- **Pengecekan**: VIF, correlation matrix\n",
        "- **Solusi**: Feature selection, regularization\n",
        "\n",
        "### 2.2 Asumsi Tambahan\n",
        "\n",
        "#### 2.2.1 Sample Size\n",
        "- **Aturan**: Minimal 10-15 observasi per variabel independen\n",
        "- **Rumus**: n ≥ 10k (k = jumlah variabel independen)\n",
        "- **Pengecekan**: Power analysis\n",
        "\n",
        "#### 2.2.2 No Outliers\n",
        "- **Definisi**: Tidak ada observasi yang ekstrem\n",
        "- **Pengecekan**: Studentized residuals, Cook's distance\n",
        "- **Solusi**: Hapus outlier, robust regression\n",
        "\n",
        "#### 2.2.3 No Missing Data\n",
        "- **Definisi**: Data lengkap untuk semua variabel\n",
        "- **Pengecekan**: Missing data analysis\n",
        "- **Solusi**: Imputation, complete case analysis\n",
        "\n",
        "### 2.3 Pengecekan Asumsi\n",
        "\n",
        "#### 2.3.1 Visual Inspection\n",
        "- **Scatter Plot Matrix**: Cek hubungan antar variabel\n",
        "- **Residual Plot**: Cek homoscedasticity\n",
        "- **Q-Q Plot**: Cek normalitas residuals\n",
        "- **Leverage Plot**: Cek outliers\n",
        "\n",
        "#### 2.3.2 Statistical Tests\n",
        "- **Durbin-Watson**: Cek independence\n",
        "- **Shapiro-Wilk**: Cek normalitas\n",
        "- **Breusch-Pagan**: Cek homoscedasticity\n",
        "- **VIF**: Cek multicollinearity\n",
        "\n",
        "### 2.4 Pelanggaran Asumsi\n",
        "\n",
        "#### 2.4.1 Non-linearity\n",
        "- **Gejala**: Residual plot menunjukkan pola non-linear\n",
        "- **Solusi**: Transformasi data, polynomial terms\n",
        "- **Contoh**: Log transformation, square root\n",
        "\n",
        "#### 2.4.2 Heteroscedasticity\n",
        "- **Gejala**: Residual plot menunjukkan pola funnel\n",
        "- **Solusi**: Transformasi data, weighted regression\n",
        "- **Contoh**: Log transformation, Box-Cox\n",
        "\n",
        "#### 2.4.3 Non-normality\n",
        "- **Gejala**: Q-Q plot tidak mengikuti garis lurus\n",
        "- **Solusi**: Transformasi data, robust regression\n",
        "- **Contoh**: Log transformation, square root\n",
        "\n",
        "#### 2.4.4 Multicollinearity\n",
        "- **Gejala**: VIF > 10, korelasi tinggi antar variabel\n",
        "- **Solusi**: Feature selection, regularization\n",
        "- **Contoh**: Ridge regression, Lasso\n",
        "\n",
        "### 2.5 Robustness\n",
        "\n",
        "#### 2.5.1 Robust Regression\n",
        "- **M-estimators**: Huber, Tukey, Hampel\n",
        "- **L-estimators**: Least absolute deviation\n",
        "- **R-estimators**: Rank-based methods\n",
        "\n",
        "#### 2.5.2 Bootstrap\n",
        "- **Bootstrap Regression**: Estimasi parameter dengan resampling\n",
        "- **Bootstrap Confidence Interval**: CI untuk parameter\n",
        "- **Bootstrap Prediction**: Interval prediksi\n",
        "\n",
        "### 2.6 Model Selection\n",
        "\n",
        "#### 2.6.1 Information Criteria\n",
        "- **AIC**: Akaike Information Criterion\n",
        "- **BIC**: Bayesian Information Criterion\n",
        "- **AICc**: Corrected AIC untuk sample kecil\n",
        "\n",
        "#### 2.6.2 Cross-validation\n",
        "- **k-fold CV**: Validasi dengan k-fold\n",
        "- **Leave-one-out CV**: Validasi dengan LOO\n",
        "- **Holdout**: Validasi dengan data terpisah\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrasi Regresi Multiple\n",
        "print(\"=== DEMONSTRASI REGRESI MULTIPLE ===\")\n",
        "\n",
        "# Data untuk demonstrasi regresi multiple\n",
        "np.random.seed(42)\n",
        "\n",
        "# 1. Data dengan 3 variabel independen\n",
        "print(\"1. DATA DENGAN 3 VARIABEL INDEPENDEN:\")\n",
        "\n",
        "# Simulasi data\n",
        "n = 100\n",
        "X1 = np.random.normal(50, 15, n)  # Variabel independen 1\n",
        "X2 = np.random.normal(30, 10, n)  # Variabel independen 2\n",
        "X3 = np.random.normal(20, 8, n)   # Variabel independen 3\n",
        "\n",
        "# Variabel dependen dengan hubungan linear\n",
        "Y = 2 * X1 + 1.5 * X2 - 0.8 * X3 + 10 + np.random.normal(0, 5, n)\n",
        "\n",
        "# Buat DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Y': Y,\n",
        "    'X1': X1,\n",
        "    'X2': X2,\n",
        "    'X3': X3\n",
        "})\n",
        "\n",
        "print(\"Data untuk Regresi Multiple:\")\n",
        "print(df.head())\n",
        "print(f\"\\nUkuran data: {df.shape}\")\n",
        "print(f\"Statistik deskriptif:\")\n",
        "print(df.describe())\n",
        "\n",
        "# 2. Regresi Multiple dengan sklearn\n",
        "print(\"\\n2. REGRESI MULTIPLE DENGAN SKLEARN:\")\n",
        "\n",
        "# Siapkan data\n",
        "X = df[['X1', 'X2', 'X3']]\n",
        "y = df['Y']\n",
        "\n",
        "# Buat model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Prediksi\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Koefisien\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "print(f\"Koefisien X1: {coefficients[0]:.4f}\")\n",
        "print(f\"Koefisien X2: {coefficients[1]:.4f}\")\n",
        "print(f\"Koefisien X3: {coefficients[2]:.4f}\")\n",
        "\n",
        "# Persamaan regresi\n",
        "print(f\"\\nPersamaan regresi:\")\n",
        "print(f\"Y = {intercept:.4f} + {coefficients[0]:.4f}X1 + {coefficients[1]:.4f}X2 + {coefficients[2]:.4f}X3\")\n",
        "\n",
        "# 3. Evaluasi Model\n",
        "print(\"\\n3. EVALUASI MODEL:\")\n",
        "\n",
        "# R-squared\n",
        "r2 = r2_score(y, y_pred)\n",
        "print(f\"R-squared: {r2:.4f}\")\n",
        "\n",
        "# Adjusted R-squared\n",
        "n = len(y)\n",
        "k = len(coefficients)\n",
        "adj_r2 = 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
        "print(f\"Adjusted R-squared: {adj_r2:.4f}\")\n",
        "\n",
        "# RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "# MAE\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "\n",
        "# 4. Korelasi antar variabel\n",
        "print(\"\\n4. KORELASI ANTAR VARIABEL:\")\n",
        "\n",
        "correlation_matrix = df.corr()\n",
        "print(\"Matriks Korelasi:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# 5. Multikolinearitas (VIF)\n",
        "print(\"\\n5. MULTIKOLINEARITAS (VIF):\")\n",
        "\n",
        "# Hitung VIF\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "print(\"Variance Inflation Factor (VIF):\")\n",
        "print(vif_data)\n",
        "\n",
        "# Interpretasi VIF\n",
        "print(\"\\nInterpretasi VIF:\")\n",
        "for i, vif in enumerate(vif_data[\"VIF\"]):\n",
        "    if vif < 5:\n",
        "        interpretation = \"Tidak ada multikolinearitas\"\n",
        "    elif vif < 10:\n",
        "        interpretation = \"Multikolinearitas sedang\"\n",
        "    else:\n",
        "        interpretation = \"Multikolinearitas tinggi\"\n",
        "    print(f\"  {vif_data['Variable'][i]}: {vif:.2f} - {interpretation}\")\n",
        "\n",
        "# 6. Visualisasi Regresi Multiple\n",
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "# Plot 1: Scatter plot matrix\n",
        "plt.subplot(3, 4, 1)\n",
        "pd.plotting.scatter_matrix(df, alpha=0.7, figsize=(8, 8), ax=plt.gca())\n",
        "plt.title('Scatter Plot Matrix')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Plot 2: Correlation heatmap\n",
        "plt.subplot(3, 4, 2)\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, fmt='.3f', ax=plt.gca())\n",
        "plt.title('Correlation Heatmap')\n",
        "\n",
        "# Plot 3: Prediksi vs Aktual\n",
        "plt.subplot(3, 4, 3)\n",
        "plt.scatter(y, y_pred, alpha=0.7, color='blue')\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', linewidth=2)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Predicted vs Actual')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Residuals vs Fitted\n",
        "plt.subplot(3, 4, 4)\n",
        "residuals = y - y_pred\n",
        "plt.scatter(y_pred, residuals, alpha=0.7, color='green')\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel('Fitted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals vs Fitted')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 5: Q-Q plot untuk normalitas residuals\n",
        "plt.subplot(3, 4, 5)\n",
        "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
        "plt.title('Q-Q Plot Residuals')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 6: Histogram residuals\n",
        "plt.subplot(3, 4, 6)\n",
        "plt.hist(residuals, bins=20, alpha=0.7, color='purple', edgecolor='black')\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram Residuals')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 7: VIF bar chart\n",
        "plt.subplot(3, 4, 7)\n",
        "plt.bar(vif_data['Variable'], vif_data['VIF'], alpha=0.7, color=['blue', 'green', 'red'])\n",
        "plt.axhline(5, color='orange', linestyle='--', label='VIF = 5')\n",
        "plt.axhline(10, color='red', linestyle='--', label='VIF = 10')\n",
        "plt.ylabel('VIF')\n",
        "plt.title('Variance Inflation Factor')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 8: Coefficients\n",
        "plt.subplot(3, 4, 8)\n",
        "variables = ['Intercept', 'X1', 'X2', 'X3']\n",
        "coeffs = [intercept] + list(coefficients)\n",
        "plt.bar(variables, coeffs, alpha=0.7, color=['purple', 'blue', 'green', 'red'])\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.title('Regression Coefficients')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 9: Residuals vs X1\n",
        "plt.subplot(3, 4, 9)\n",
        "plt.scatter(X1, residuals, alpha=0.7, color='blue')\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals vs X1')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 10: Residuals vs X2\n",
        "plt.subplot(3, 4, 10)\n",
        "plt.scatter(X2, residuals, alpha=0.7, color='green')\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel('X2')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals vs X2')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 11: Residuals vs X3\n",
        "plt.subplot(3, 4, 11)\n",
        "plt.scatter(X3, residuals, alpha=0.7, color='red')\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel('X3')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals vs X3')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 12: Model summary\n",
        "plt.subplot(3, 4, 12)\n",
        "plt.axis('off')\n",
        "summary_text = f\"\"\"\n",
        "REGRESI MULTIPLE SUMMARY\n",
        "\n",
        "Model:\n",
        "Y = {intercept:.4f} + {coefficients[0]:.4f}X1 + {coefficients[1]:.4f}X2 + {coefficients[2]:.4f}X3\n",
        "\n",
        "Goodness of Fit:\n",
        "R² = {r2:.4f}\n",
        "Adjusted R² = {adj_r2:.4f}\n",
        "RMSE = {rmse:.4f}\n",
        "MAE = {mae:.4f}\n",
        "\n",
        "Multikolinearitas:\n",
        "X1 VIF = {vif_data['VIF'][0]:.2f}\n",
        "X2 VIF = {vif_data['VIF'][1]:.2f}\n",
        "X3 VIF = {vif_data['VIF'][2]:.2f}\n",
        "\n",
        "Interpretasi:\n",
        "- R²: {r2*100:.1f}% varians Y dijelaskan oleh model\n",
        "- RMSE: Rata-rata error prediksi = {rmse:.2f}\n",
        "- VIF < 5: Tidak ada multikolinearitas\n",
        "\"\"\"\n",
        "plt.text(0.1, 0.9, summary_text, transform=plt.gca().transAxes, fontsize=8, \n",
        "         verticalalignment='top', fontfamily='monospace')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 7. Interpretasi Hasil\n",
        "print(\"\\n7. INTERPRETASI HASIL:\")\n",
        "\n",
        "print(f\"\\nModel Regresi Multiple:\")\n",
        "print(f\"  - Intercept: {intercept:.4f}\")\n",
        "print(f\"    Interpretasi: Nilai Y ketika semua X = 0\")\n",
        "print(f\"  - Koefisien X1: {coefficients[0]:.4f}\")\n",
        "print(f\"    Interpretasi: Setiap peningkatan 1 unit X1, Y meningkat {coefficients[0]:.4f} unit (mengontrol X2 dan X3)\")\n",
        "print(f\"  - Koefisien X2: {coefficients[1]:.4f}\")\n",
        "print(f\"    Interpretasi: Setiap peningkatan 1 unit X2, Y meningkat {coefficients[1]:.4f} unit (mengontrol X1 dan X3)\")\n",
        "print(f\"  - Koefisien X3: {coefficients[2]:.4f}\")\n",
        "print(f\"    Interpretasi: Setiap peningkatan 1 unit X3, Y menurun {abs(coefficients[2]):.4f} unit (mengontrol X1 dan X2)\")\n",
        "\n",
        "print(f\"\\nGoodness of Fit:\")\n",
        "print(f\"  - R²: {r2:.4f} ({r2*100:.1f}% varians Y dijelaskan oleh model)\")\n",
        "print(f\"  - Adjusted R²: {adj_r2:.4f} (R² yang disesuaikan untuk jumlah variabel)\")\n",
        "print(f\"  - RMSE: {rmse:.4f} (Rata-rata error prediksi)\")\n",
        "print(f\"  - MAE: {mae:.4f} (Rata-rata absolute error)\")\n",
        "\n",
        "print(f\"\\nMultikolinearitas:\")\n",
        "for i, vif in enumerate(vif_data[\"VIF\"]):\n",
        "    if vif < 5:\n",
        "        interpretation = \"Tidak ada multikolinearitas\"\n",
        "    elif vif < 10:\n",
        "        interpretation = \"Multikolinearitas sedang\"\n",
        "    else:\n",
        "        interpretation = \"Multikolinearitas tinggi\"\n",
        "    print(f\"  - {vif_data['Variable'][i]}: VIF = {vif:.2f} - {interpretation}\")\n",
        "\n",
        "# 8. Kesimpulan dan Rekomendasi\n",
        "print(\"\\n8. KESIMPULAN DAN REKOMENDASI:\")\n",
        "print(\"   - Regresi Multiple: Model hubungan linear dengan beberapa variabel independen\")\n",
        "print(\"   - Koefisien: Interpretasi dengan mengontrol variabel lain\")\n",
        "print(\"   - R²: Proporsi varians yang dijelaskan oleh model\")\n",
        "print(\"   - VIF: Ukuran multikolinearitas (VIF < 5 ideal)\")\n",
        "print(\"   - Asumsi: Linear relationship, normality, homoscedasticity, independence\")\n",
        "print(\"   - Diagnostik: Periksa residuals, multikolinearitas, outliers\")\n",
        "print(\"   - Aplikasi: Prediksi, kontrol, penjelasan, optimasi\")\n",
        "print(\"   - Best practice: Validasi model, periksa asumsi, hindari overfitting\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Feature Selection dan Regularisasi\n",
        "\n",
        "### 6.1 Feature Selection\n",
        "\n",
        "#### 6.1.1 Forward Selection\n",
        "- **Prinsip**: Mulai dengan model kosong, tambahkan variabel satu per satu\n",
        "- **Kriteria**: Pilih variabel yang memberikan peningkatan terbesar pada R²\n",
        "- **Keunggulan**: Sederhana, mudah diimplementasikan\n",
        "- **Kekurangan**: Tidak mempertimbangkan interaksi antar variabel\n",
        "\n",
        "#### 6.1.2 Backward Elimination\n",
        "- **Prinsip**: Mulai dengan semua variabel, hapus variabel satu per satu\n",
        "- **Kriteria**: Hapus variabel yang memberikan penurunan terkecil pada R²\n",
        "- **Keunggulan**: Mempertimbangkan semua variabel awal\n",
        "- **Kekurangan**: Dapat menghapus variabel penting\n",
        "\n",
        "#### 6.1.3 Stepwise Selection\n",
        "- **Prinsip**: Kombinasi forward dan backward selection\n",
        "- **Kriteria**: Tambahkan variabel yang signifikan, hapus yang tidak signifikan\n",
        "- **Keunggulan**: Lebih komprehensif\n",
        "- **Kekurangan**: Dapat overfit\n",
        "\n",
        "#### 6.1.4 Best Subset Selection\n",
        "- **Prinsip**: Evaluasi semua kombinasi variabel\n",
        "- **Kriteria**: Pilih model dengan AIC/BIC terbaik\n",
        "- **Keunggulan**: Optimal secara teoritis\n",
        "- **Kekurangan**: Computationally expensive\n",
        "\n",
        "### 6.2 Regularisasi\n",
        "\n",
        "#### 6.2.1 Ridge Regression (L2)\n",
        "- **Prinsip**: Menambahkan penalty pada sum of squared coefficients\n",
        "- **Rumus**: min(SSR + λΣβᵢ²)\n",
        "- **Efek**: Menyusutkan koefisien menuju 0\n",
        "- **Keunggulan**: Mengurangi overfitting, menangani multikolinearitas\n",
        "- **Kekurangan**: Tidak melakukan feature selection\n",
        "\n",
        "#### 6.2.2 Lasso Regression (L1)\n",
        "- **Prinsip**: Menambahkan penalty pada sum of absolute coefficients\n",
        "- **Rumus**: min(SSR + λΣ|βᵢ|)\n",
        "- **Efek**: Menyusutkan koefisien ke 0 (feature selection)\n",
        "- **Keunggulan**: Feature selection otomatis\n",
        "- **Kekurangan**: Dapat menghapus variabel penting\n",
        "\n",
        "#### 6.2.3 Elastic Net\n",
        "- **Prinsip**: Kombinasi Ridge dan Lasso\n",
        "- **Rumus**: min(SSR + λ₁Σ|βᵢ| + λ₂Σβᵢ²)\n",
        "- **Efek**: Kombinasi feature selection dan shrinkage\n",
        "- **Keunggulan**: Mengatasi keterbatasan Ridge dan Lasso\n",
        "- **Kekurangan**: Lebih kompleks\n",
        "\n",
        "### 6.3 Cross-Validation\n",
        "\n",
        "#### 6.3.1 k-Fold Cross-Validation\n",
        "- **Prinsip**: Bagi data menjadi k subset, train pada k-1 subset, test pada 1 subset\n",
        "- **Kriteria**: Pilih k = 5 atau 10\n",
        "- **Keunggulan**: Mengurangi bias, estimasi yang lebih stabil\n",
        "- **Kekurangan**: Computationally expensive\n",
        "\n",
        "#### 6.3.2 Leave-One-Out Cross-Validation\n",
        "- **Prinsip**: Train pada n-1 observasi, test pada 1 observasi\n",
        "- **Kriteria**: Ulangi untuk semua observasi\n",
        "- **Keunggulan**: Menggunakan semua data untuk training\n",
        "- **Kekurangan**: Computationally expensive untuk data besar\n",
        "\n",
        "#### 6.3.3 Holdout Validation\n",
        "- **Prinsip**: Bagi data menjadi training dan testing set\n",
        "- **Kriteria**: 70-80% training, 20-30% testing\n",
        "- **Keunggulan**: Sederhana, cepat\n",
        "- **Kekurangan**: Dapat bias jika data tidak representatif\n",
        "\n",
        "### 6.4 Model Selection Criteria\n",
        "\n",
        "#### 6.4.1 AIC (Akaike Information Criterion)\n",
        "- **Rumus**: AIC = 2k - 2ln(L)\n",
        "- **Prinsip**: Balance antara goodness of fit dan complexity\n",
        "- **Interpretasi**: Semakin kecil semakin baik\n",
        "- **Keterbatasan**: Tidak mempertimbangkan sample size\n",
        "\n",
        "#### 6.4.2 BIC (Bayesian Information Criterion)\n",
        "- **Rumus**: BIC = k*ln(n) - 2ln(L)\n",
        "- **Prinsip**: Lebih konservatif daripada AIC\n",
        "- **Interpretasi**: Semakin kecil semakin baik\n",
        "- **Keunggulan**: Mempertimbangkan sample size\n",
        "\n",
        "#### 6.4.3 AICc (Corrected AIC)\n",
        "- **Rumus**: AICc = AIC + 2k(k+1)/(n-k-1)\n",
        "- **Prinsip**: Koreksi AIC untuk sample kecil\n",
        "- **Interpretasi**: Semakin kecil semakin baik\n",
        "- **Aplikasi**: Sample size kecil (n/k < 40)\n",
        "\n",
        "### 6.5 Feature Engineering\n",
        "\n",
        "#### 6.5.1 Polynomial Features\n",
        "- **Prinsip**: Tambahkan pangkat variabel (X², X³, ...)\n",
        "- **Aplikasi**: Hubungan non-linear\n",
        "- **Keunggulan**: Menangkap non-linearity\n",
        "- **Kekurangan**: Dapat overfit\n",
        "\n",
        "#### 6.5.2 Interaction Terms\n",
        "- **Prinsip**: Tambahkan perkalian variabel (X1*X2, X1*X3, ...)\n",
        "- **Aplikasi**: Efek interaksi antar variabel\n",
        "- **Keunggulan**: Menangkap interaksi\n",
        "- **Kekurangan**: Dapat overfit\n",
        "\n",
        "#### 6.5.3 Dummy Variables\n",
        "- **Prinsip**: Konversi variabel kategoris menjadi dummy variables\n",
        "- **Aplikasi**: Variabel kategoris\n",
        "- **Keunggulan**: Dapat menggunakan variabel kategoris\n",
        "- **Kekurangan**: Dapat multikolinearitas\n",
        "\n",
        "### 6.6 Dimensionality Reduction\n",
        "\n",
        "#### 6.6.1 Principal Component Analysis (PCA)\n",
        "- **Prinsip**: Transformasi variabel menjadi komponen utama\n",
        "- **Aplikasi**: Mengurangi dimensi, menghilangkan multikolinearitas\n",
        "- **Keunggulan**: Menghilangkan multikolinearitas\n",
        "- **Kekurangan**: Sulit diinterpretasikan\n",
        "\n",
        "#### 6.6.2 Partial Least Squares (PLS)\n",
        "- **Prinsip**: Kombinasi PCA dan regression\n",
        "- **Aplikasi**: Prediksi dengan variabel banyak\n",
        "- **Keunggulan**: Menangani multikolinearitas\n",
        "- **Kekurangan**: Sulit diinterpretasikan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrasi Feature Selection dan Regularisasi\n",
        "print(\"=== DEMONSTRASI FEATURE SELECTION DAN REGULARISASI ===\")\n",
        "\n",
        "# Data untuk demonstrasi feature selection dan regularisasi\n",
        "np.random.seed(42)\n",
        "\n",
        "# 1. Data dengan banyak variabel (untuk demonstrasi feature selection)\n",
        "print(\"1. DATA DENGAN BANYAK VARIABEL:\")\n",
        "\n",
        "# Simulasi data dengan 10 variabel independen\n",
        "n = 200\n",
        "X = np.random.normal(0, 1, (n, 10))\n",
        "# Hanya 5 variabel pertama yang berpengaruh\n",
        "y = 2 * X[:, 0] + 1.5 * X[:, 1] - 0.8 * X[:, 2] + 0.5 * X[:, 3] - 0.3 * X[:, 4] + np.random.normal(0, 0.5, n)\n",
        "\n",
        "# Buat DataFrame\n",
        "feature_names = [f'X{i+1}' for i in range(10)]\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df['Y'] = y\n",
        "\n",
        "print(\"Data untuk Feature Selection:\")\n",
        "print(df.head())\n",
        "print(f\"\\nUkuran data: {df.shape}\")\n",
        "\n",
        "# 2. Forward Selection\n",
        "print(\"\\n2. FORWARD SELECTION:\")\n",
        "\n",
        "from sklearn.feature_selection import f_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Hitung F-statistik untuk setiap variabel\n",
        "f_scores, p_values = f_regression(X, y)\n",
        "\n",
        "# Urutkan berdasarkan F-statistik\n",
        "feature_ranking = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'F_Score': f_scores,\n",
        "    'P_Value': p_values\n",
        "}).sort_values('F_Score', ascending=False)\n",
        "\n",
        "print(\"Ranking variabel berdasarkan F-statistik:\")\n",
        "print(feature_ranking)\n",
        "\n",
        "# Forward selection manual\n",
        "selected_features = []\n",
        "remaining_features = feature_names.copy()\n",
        "best_r2 = 0\n",
        "\n",
        "print(\"\\nForward Selection Process:\")\n",
        "for i in range(min(5, len(remaining_features))):  # Pilih 5 variabel terbaik\n",
        "    best_feature = None\n",
        "    best_r2_increase = 0\n",
        "    \n",
        "    for feature in remaining_features:\n",
        "        # Test menambahkan feature ini\n",
        "        test_features = selected_features + [feature]\n",
        "        X_test = df[test_features]\n",
        "        \n",
        "        model = LinearRegression()\n",
        "        model.fit(X_test, y)\n",
        "        y_pred = model.predict(X_test)\n",
        "        r2 = r2_score(y, y_pred)\n",
        "        \n",
        "        r2_increase = r2 - best_r2\n",
        "        if r2_increase > best_r2_increase:\n",
        "            best_r2_increase = r2_increase\n",
        "            best_feature = feature\n",
        "            best_r2 = r2\n",
        "    \n",
        "    if best_feature:\n",
        "        selected_features.append(best_feature)\n",
        "        remaining_features.remove(best_feature)\n",
        "        print(f\"  Step {i+1}: Tambahkan {best_feature}, R² = {best_r2:.4f}\")\n",
        "\n",
        "print(f\"\\nVariabel terpilih: {selected_features}\")\n",
        "\n",
        "# 3. Backward Elimination\n",
        "print(\"\\n3. BACKWARD ELIMINATION:\")\n",
        "\n",
        "# Mulai dengan semua variabel\n",
        "all_features = feature_names.copy()\n",
        "current_features = all_features.copy()\n",
        "\n",
        "print(\"Backward Elimination Process:\")\n",
        "for i in range(len(all_features) - 5):  # Hapus sampai 5 variabel tersisa\n",
        "    worst_feature = None\n",
        "    best_r2_after_removal = 0\n",
        "    \n",
        "    for feature in current_features:\n",
        "        # Test menghapus feature ini\n",
        "        test_features = [f for f in current_features if f != feature]\n",
        "        X_test = df[test_features]\n",
        "        \n",
        "        model = LinearRegression()\n",
        "        model.fit(X_test, y)\n",
        "        y_pred = model.predict(X_test)\n",
        "        r2 = r2_score(y, y_pred)\n",
        "        \n",
        "        if r2 > best_r2_after_removal:\n",
        "            best_r2_after_removal = r2\n",
        "            worst_feature = feature\n",
        "    \n",
        "    if worst_feature:\n",
        "        current_features.remove(worst_feature)\n",
        "        print(f\"  Step {i+1}: Hapus {worst_feature}, R² = {best_r2_after_removal:.4f}\")\n",
        "\n",
        "print(f\"\\nVariabel tersisa: {current_features}\")\n",
        "\n",
        "# 4. Regularisasi (Ridge, Lasso, Elastic Net)\n",
        "print(\"\\n4. REGULARISASI:\")\n",
        "\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Ridge Regression\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X, y)\n",
        "ridge_coef = ridge.coef_\n",
        "\n",
        "# Lasso Regression\n",
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(X, y)\n",
        "lasso_coef = lasso.coef_\n",
        "\n",
        "# Elastic Net\n",
        "elastic = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "elastic.fit(X, y)\n",
        "elastic_coef = elastic.coef_\n",
        "\n",
        "# Bandingkan koefisien\n",
        "coef_comparison = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'True': [2, 1.5, -0.8, 0.5, -0.3, 0, 0, 0, 0, 0],\n",
        "    'Ridge': ridge_coef,\n",
        "    'Lasso': lasso_coef,\n",
        "    'Elastic': elastic_coef\n",
        "})\n",
        "\n",
        "print(\"Perbandingan Koefisien:\")\n",
        "print(coef_comparison)\n",
        "\n",
        "# 5. Cross-Validation\n",
        "print(\"\\n5. CROSS-VALIDATION:\")\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# K-Fold Cross-Validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Linear Regression\n",
        "lr_scores = cross_val_score(LinearRegression(), X, y, cv=kfold, scoring='r2')\n",
        "print(f\"Linear Regression - R² CV: {lr_scores.mean():.4f} (+/- {lr_scores.std() * 2:.4f})\")\n",
        "\n",
        "# Ridge Regression\n",
        "ridge_scores = cross_val_score(Ridge(alpha=1.0), X, y, cv=kfold, scoring='r2')\n",
        "print(f\"Ridge Regression - R² CV: {ridge_scores.mean():.4f} (+/- {ridge_scores.std() * 2:.4f})\")\n",
        "\n",
        "# Lasso Regression\n",
        "lasso_scores = cross_val_score(Lasso(alpha=0.1), X, y, cv=kfold, scoring='r2')\n",
        "print(f\"Lasso Regression - R² CV: {lasso_scores.mean():.4f} (+/- {lasso_scores.std() * 2:.4f})\")\n",
        "\n",
        "# Elastic Net\n",
        "elastic_scores = cross_val_score(ElasticNet(alpha=0.1, l1_ratio=0.5), X, y, cv=kfold, scoring='r2')\n",
        "print(f\"Elastic Net - R² CV: {elastic_scores.mean():.4f} (+/- {elastic_scores.std() * 2:.4f})\")\n",
        "\n",
        "# 6. Model Selection dengan AIC/BIC\n",
        "print(\"\\n6. MODEL SELECTION DENGAN AIC/BIC:\")\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def calculate_aic_bic(model, X, y):\n",
        "    y_pred = model.predict(X)\n",
        "    mse = mean_squared_error(y, y_pred)\n",
        "    n = len(y)\n",
        "    k = X.shape[1] + 1  # +1 untuk intercept\n",
        "    \n",
        "    # AIC\n",
        "    aic = n * np.log(mse) + 2 * k\n",
        "    \n",
        "    # BIC\n",
        "    bic = n * np.log(mse) + k * np.log(n)\n",
        "    \n",
        "    return aic, bic\n",
        "\n",
        "# Hitung AIC/BIC untuk model yang berbeda\n",
        "models = {\n",
        "    'Linear': LinearRegression(),\n",
        "    'Ridge': Ridge(alpha=1.0),\n",
        "    'Lasso': Lasso(alpha=0.1),\n",
        "    'Elastic': ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "}\n",
        "\n",
        "model_scores = pd.DataFrame(columns=['Model', 'AIC', 'BIC', 'R²'])\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X, y)\n",
        "    aic, bic = calculate_aic_bic(model, X, y)\n",
        "    r2 = r2_score(y, model.predict(X))\n",
        "    \n",
        "    model_scores = pd.concat([model_scores, pd.DataFrame({\n",
        "        'Model': [name],\n",
        "        'AIC': [aic],\n",
        "        'BIC': [bic],\n",
        "        'R²': [r2]\n",
        "    })], ignore_index=True)\n",
        "\n",
        "print(\"Perbandingan Model:\")\n",
        "print(model_scores)\n",
        "\n",
        "# 7. Visualisasi Feature Selection dan Regularisasi\n",
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "# Plot 1: F-statistik untuk feature selection\n",
        "plt.subplot(3, 4, 1)\n",
        "plt.bar(feature_ranking['Feature'], feature_ranking['F_Score'], alpha=0.7, color='blue')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('F-Score')\n",
        "plt.title('F-Score untuk Feature Selection')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: P-values untuk feature selection\n",
        "plt.subplot(3, 4, 2)\n",
        "plt.bar(feature_ranking['Feature'], feature_ranking['P_Value'], alpha=0.7, color='red')\n",
        "plt.axhline(0.05, color='orange', linestyle='--', label='α = 0.05')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('P-Value')\n",
        "plt.title('P-Values untuk Feature Selection')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Perbandingan koefisien\n",
        "plt.subplot(3, 4, 3)\n",
        "x_pos = np.arange(len(feature_names))\n",
        "width = 0.2\n",
        "\n",
        "plt.bar(x_pos - width, coef_comparison['True'], width, label='True', alpha=0.7)\n",
        "plt.bar(x_pos, coef_comparison['Ridge'], width, label='Ridge', alpha=0.7)\n",
        "plt.bar(x_pos + width, coef_comparison['Lasso'], width, label='Lasso', alpha=0.7)\n",
        "plt.bar(x_pos + 2*width, coef_comparison['Elastic'], width, label='Elastic', alpha=0.7)\n",
        "\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.title('Perbandingan Koefisien')\n",
        "plt.xticks(x_pos, feature_names, rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Cross-validation scores\n",
        "plt.subplot(3, 4, 4)\n",
        "cv_scores = [lr_scores.mean(), ridge_scores.mean(), lasso_scores.mean(), elastic_scores.mean()]\n",
        "cv_errors = [lr_scores.std(), ridge_scores.std(), lasso_scores.std(), elastic_scores.std()]\n",
        "model_names = ['Linear', 'Ridge', 'Lasso', 'Elastic']\n",
        "\n",
        "plt.bar(model_names, cv_scores, alpha=0.7, color=['blue', 'green', 'red', 'purple'])\n",
        "plt.errorbar(model_names, cv_scores, yerr=cv_errors, fmt='none', color='black', capsize=5)\n",
        "plt.ylabel('R² CV Score')\n",
        "plt.title('Cross-Validation Scores')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 5: AIC comparison\n",
        "plt.subplot(3, 4, 5)\n",
        "plt.bar(model_scores['Model'], model_scores['AIC'], alpha=0.7, color='blue')\n",
        "plt.ylabel('AIC')\n",
        "plt.title('AIC Comparison')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 6: BIC comparison\n",
        "plt.subplot(3, 4, 6)\n",
        "plt.bar(model_scores['Model'], model_scores['BIC'], alpha=0.7, color='green')\n",
        "plt.ylabel('BIC')\n",
        "plt.title('BIC Comparison')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 7: R² comparison\n",
        "plt.subplot(3, 4, 7)\n",
        "plt.bar(model_scores['Model'], model_scores['R²'], alpha=0.7, color='red')\n",
        "plt.ylabel('R²')\n",
        "plt.title('R² Comparison')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 8: Feature importance (Lasso)\n",
        "plt.subplot(3, 4, 8)\n",
        "lasso_importance = np.abs(lasso_coef)\n",
        "plt.bar(feature_names, lasso_importance, alpha=0.7, color='orange')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('|Coefficient|')\n",
        "plt.title('Feature Importance (Lasso)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 9: Regularization path (Lasso)\n",
        "plt.subplot(3, 4, 9)\n",
        "alphas = np.logspace(-4, 1, 50)\n",
        "lasso_path = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    lasso_temp = Lasso(alpha=alpha)\n",
        "    lasso_temp.fit(X, y)\n",
        "    lasso_path.append(lasso_temp.coef_)\n",
        "\n",
        "lasso_path = np.array(lasso_path)\n",
        "\n",
        "for i in range(len(feature_names)):\n",
        "    plt.plot(alphas, lasso_path[:, i], label=f'X{i+1}', alpha=0.7)\n",
        "\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.title('Lasso Regularization Path')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 10: Regularization path (Ridge)\n",
        "plt.subplot(3, 4, 10)\n",
        "ridge_path = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    ridge_temp = Ridge(alpha=alpha)\n",
        "    ridge_temp.fit(X, y)\n",
        "    ridge_path.append(ridge_temp.coef_)\n",
        "\n",
        "ridge_path = np.array(ridge_path)\n",
        "\n",
        "for i in range(len(feature_names)):\n",
        "    plt.plot(alphas, ridge_path[:, i], label=f'X{i+1}', alpha=0.7)\n",
        "\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.title('Ridge Regularization Path')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 11: Model complexity vs performance\n",
        "plt.subplot(3, 4, 11)\n",
        "complexity = [1, 2, 3, 4, 5]  # Jumlah fitur\n",
        "performance = []\n",
        "\n",
        "for i in range(1, 6):\n",
        "    features = selected_features[:i]\n",
        "    X_subset = df[features]\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_subset, y)\n",
        "    y_pred = model.predict(X_subset)\n",
        "    r2 = r2_score(y, y_pred)\n",
        "    performance.append(r2)\n",
        "\n",
        "plt.plot(complexity, performance, 'bo-', linewidth=2, markersize=8)\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('R²')\n",
        "plt.title('Model Complexity vs Performance')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 12: Summary\n",
        "plt.subplot(3, 4, 12)\n",
        "plt.axis('off')\n",
        "summary_text = f\"\"\"\n",
        "FEATURE SELECTION & REGULARIZATION SUMMARY\n",
        "\n",
        "Forward Selection:\n",
        "Selected: {selected_features}\n",
        "\n",
        "Backward Elimination:\n",
        "Remaining: {current_features}\n",
        "\n",
        "Regularization:\n",
        "Ridge: R² = {ridge_scores.mean():.4f}\n",
        "Lasso: R² = {lasso_scores.mean():.4f}\n",
        "Elastic: R² = {elastic_scores.mean():.4f}\n",
        "\n",
        "Model Selection:\n",
        "Best AIC: {model_scores.loc[model_scores['AIC'].idxmin(), 'Model']}\n",
        "Best BIC: {model_scores.loc[model_scores['BIC'].idxmin(), 'Model']}\n",
        "Best R²: {model_scores.loc[model_scores['R²'].idxmax(), 'Model']}\n",
        "\n",
        "Recommendations:\n",
        "- Use forward selection for feature selection\n",
        "- Use Ridge for multicollinearity\n",
        "- Use Lasso for feature selection\n",
        "- Use Elastic Net for balanced approach\n",
        "\"\"\"\n",
        "plt.text(0.1, 0.9, summary_text, transform=plt.gca().transAxes, fontsize=8, \n",
        "         verticalalignment='top', fontfamily='monospace')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 8. Interpretasi Hasil\n",
        "print(\"\\n8. INTERPRETASI HASIL:\")\n",
        "\n",
        "print(f\"\\nFeature Selection:\")\n",
        "print(f\"  - Forward Selection: {selected_features}\")\n",
        "print(f\"  - Backward Elimination: {current_features}\")\n",
        "print(f\"  - F-statistik: Variabel dengan F-score tertinggi paling penting\")\n",
        "\n",
        "print(f\"\\nRegularisasi:\")\n",
        "print(f\"  - Ridge: Menyusutkan koefisien, tidak menghapus variabel\")\n",
        "print(f\"  - Lasso: Menyusutkan koefisien ke 0, melakukan feature selection\")\n",
        "print(f\"  - Elastic Net: Kombinasi Ridge dan Lasso\")\n",
        "\n",
        "print(f\"\\nCross-Validation:\")\n",
        "print(f\"  - Linear Regression: R² = {lr_scores.mean():.4f}\")\n",
        "print(f\"  - Ridge Regression: R² = {ridge_scores.mean():.4f}\")\n",
        "print(f\"  - Lasso Regression: R² = {lasso_scores.mean():.4f}\")\n",
        "print(f\"  - Elastic Net: R² = {elastic_scores.mean():.4f}\")\n",
        "\n",
        "print(f\"\\nModel Selection:\")\n",
        "print(f\"  - AIC: {model_scores.loc[model_scores['AIC'].idxmin(), 'Model']} (terbaik)\")\n",
        "print(f\"  - BIC: {model_scores.loc[model_scores['BIC'].idxmin(), 'Model']} (terbaik)\")\n",
        "print(f\"  - R²: {model_scores.loc[model_scores['R²'].idxmax(), 'Model']} (terbaik)\")\n",
        "\n",
        "# 9. Kesimpulan dan Rekomendasi\n",
        "print(\"\\n9. KESIMPULAN DAN REKOMENDASI:\")\n",
        "print(\"   - Feature Selection: Pilih variabel yang paling berpengaruh\")\n",
        "print(\"   - Regularisasi: Gunakan untuk mengatasi overfitting\")\n",
        "print(\"   - Cross-Validation: Validasi model dengan data independen\")\n",
        "print(\"   - Model Selection: Gunakan AIC/BIC untuk memilih model terbaik\")\n",
        "print(\"   - Ridge: Untuk multikolinearitas\")\n",
        "print(\"   - Lasso: Untuk feature selection\")\n",
        "print(\"   - Elastic Net: Untuk pendekatan seimbang\")\n",
        "print(\"   - Best practice: Kombinasi feature selection dan regularisasi\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Interpretasi Koefisien (Coefficient Interpretation)\n",
        "\n",
        "### 3.1 Interpretasi Koefisien Regresi\n",
        "\n",
        "#### 3.1.1 Koefisien Parsial\n",
        "- **Definisi**: Koefisien regresi mengukur perubahan rata-rata dalam variabel dependen untuk setiap unit perubahan dalam variabel independen, sambil mengontrol variabel independen lainnya\n",
        "- **Rumus**: βᵢ = ∂Y/∂Xᵢ (holding other variables constant)\n",
        "- **Interpretasi**: \"Mengontrol variabel lain, setiap peningkatan 1 unit Xᵢ akan mengubah Y sebesar βᵢ unit\"\n",
        "\n",
        "#### 3.1.2 Intercept (β₀)\n",
        "- **Definisi**: Nilai prediksi Y ketika semua variabel independen = 0\n",
        "- **Interpretasi**: \"Ketika semua X = 0, nilai prediksi Y adalah β₀\"\n",
        "- **Catatan**: Mungkin tidak bermakna praktis jika X tidak bisa = 0\n",
        "\n",
        "#### 3.1.3 Slope Coefficients (β₁, β₂, ..., βₖ)\n",
        "- **Definisi**: Perubahan Y per unit perubahan Xᵢ\n",
        "- **Interpretasi**: \"Mengontrol variabel lain, setiap peningkatan 1 unit Xᵢ akan mengubah Y sebesar βᵢ unit\"\n",
        "- **Arah**: Positif = peningkatan Y, Negatif = penurunan Y\n",
        "\n",
        "### 3.2 Standardized Coefficients\n",
        "\n",
        "#### 3.2.1 Beta Coefficients\n",
        "- **Rumus**: βᵢ_std = βᵢ × (σXᵢ / σY)\n",
        "- **Interpretasi**: Perubahan standar deviasi Y per perubahan standar deviasi Xᵢ\n",
        "- **Keunggulan**: Dapat membandingkan pengaruh relatif antar variabel\n",
        "- **Aplikasi**: Variabel dengan skala berbeda\n",
        "\n",
        "#### 3.2.2 Perbandingan Pengaruh\n",
        "- **Prinsip**: Koefisien terstandarisasi yang lebih besar menunjukkan pengaruh yang lebih kuat\n",
        "- **Contoh**: β₁_std = 0.5, β₂_std = 0.3 → X₁ memiliki pengaruh lebih kuat\n",
        "- **Keterbatasan**: Tidak mengukur signifikansi statistik\n",
        "\n",
        "### 3.3 Confidence Intervals\n",
        "\n",
        "#### 3.3.1 Confidence Interval untuk Koefisien\n",
        "- **Rumus**: CI = βᵢ ± t(α/2, n-k-1) × SE(βᵢ)\n",
        "- **Interpretasi**: Interval yang mengandung nilai sebenarnya dengan probabilitas (1-α)\n",
        "- **Aplikasi**: Estimasi ketidakpastian parameter\n",
        "\n",
        "#### 3.3.2 Significance Testing\n",
        "- **Hipotesis**: H₀: βᵢ = 0 vs H₁: βᵢ ≠ 0\n",
        "- **Statistik**: t = βᵢ / SE(βᵢ)\n",
        "- **Keputusan**: Tolak H₀ jika |t| > t_critical atau p-value < α\n",
        "\n",
        "### 3.4 Interaction Effects\n",
        "\n",
        "#### 3.4.1 Interaction Terms\n",
        "- **Definisi**: Perkalian antar variabel independen (X₁ × X₂)\n",
        "- **Interpretasi**: Pengaruh X₁ bergantung pada nilai X₂\n",
        "- **Rumus**: Y = β₀ + β₁X₁ + β₂X₂ + β₃(X₁ × X₂) + ε\n",
        "\n",
        "#### 3.4.2 Interpretasi Interaction\n",
        "- **Koefisien X₁**: Pengaruh X₁ ketika X₂ = 0\n",
        "- **Koefisien X₂**: Pengaruh X₂ ketika X₁ = 0\n",
        "- **Koefisien Interaction**: Perubahan pengaruh X₁ per unit X₂\n",
        "\n",
        "### 3.5 Dummy Variables\n",
        "\n",
        "#### 3.5.1 Dummy Variable Coding\n",
        "- **Binary**: 0 dan 1 untuk dua kategori\n",
        "- **Multiple Categories**: k-1 dummy variables untuk k kategori\n",
        "- **Reference Category**: Kategori yang tidak memiliki dummy variable\n",
        "\n",
        "#### 3.5.2 Interpretasi Dummy Variables\n",
        "- **Koefisien**: Perbedaan rata-rata antara kategori dan reference category\n",
        "- **Contoh**: β = 5 → Kategori ini 5 unit lebih tinggi dari reference category\n",
        "- **Catatan**: Mengontrol variabel lain\n",
        "\n",
        "### 3.6 Non-linear Effects\n",
        "\n",
        "#### 3.6.1 Polynomial Terms\n",
        "- **Quadratic**: X² untuk efek kuadratik\n",
        "- **Cubic**: X³ untuk efek kubik\n",
        "- **Interpretasi**: Perubahan pengaruh X pada Y\n",
        "\n",
        "#### 3.6.2 Log Transformations\n",
        "- **Log-Log**: ln(Y) = β₀ + β₁ln(X₁) + β₂ln(X₂) + ε\n",
        "- **Interpretasi**: βᵢ = elastisitas Y terhadap Xᵢ\n",
        "- **Aplikasi**: Hubungan proporsional\n",
        "\n",
        "### 3.7 Common Pitfalls\n",
        "\n",
        "#### 3.7.1 Simpson's Paradox\n",
        "- **Definisi**: Arah hubungan berubah ketika variabel kontrol ditambahkan\n",
        "- **Penyebab**: Confounding variables\n",
        "- **Solusi**: Analisis multivariat yang tepat\n",
        "\n",
        "#### 3.7.2 Ecological Fallacy\n",
        "- **Definisi**: Menyimpulkan hubungan individual dari data agregat\n",
        "- **Contoh**: Korelasi tingkat negara ≠ korelasi individual\n",
        "- **Solusi**: Gunakan data individual\n",
        "\n",
        "#### 3.7.3 Omitted Variable Bias\n",
        "- **Definisi**: Mengabaikan variabel penting yang berkorelasi dengan variabel independen\n",
        "- **Efek**: Koefisien bias\n",
        "- **Solusi**: Masukkan semua variabel relevan\n",
        "\n",
        "### 3.8 Practical Guidelines\n",
        "\n",
        "#### 3.8.1 Interpretasi yang Benar\n",
        "- **Konteks**: Pertimbangkan konteks penelitian\n",
        "- **Magnitude**: Perhatikan besaran koefisien\n",
        "- **Significance**: Perhatikan signifikansi statistik\n",
        "- **Confidence**: Gunakan confidence interval\n",
        "\n",
        "#### 3.8.2 Komunikasi Hasil\n",
        "- **Bahasa Sederhana**: Gunakan bahasa yang mudah dipahami\n",
        "- **Angka Konkret**: Berikan contoh numerik\n",
        "- **Keterbatasan**: Diskusikan keterbatasan interpretasi\n",
        "- **Implikasi**: Jelaskan implikasi praktis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluasi Model (Model Evaluation)\n",
        "\n",
        "### 4.1 Goodness of Fit Measures\n",
        "\n",
        "#### 4.1.1 R-squared (R²)\n",
        "- **Definisi**: Proporsi varians dalam Y yang dijelaskan oleh model\n",
        "- **Rumus**: R² = 1 - (SSR / SST) = SSReg / SST\n",
        "- **Range**: 0 ≤ R² ≤ 1\n",
        "- **Interpretasi**: Semakin tinggi semakin baik\n",
        "- **Keterbatasan**: Tidak mempertimbangkan jumlah variabel\n",
        "\n",
        "#### 4.1.2 Adjusted R-squared (R²adj)\n",
        "- **Definisi**: R² yang disesuaikan untuk jumlah variabel independen\n",
        "- **Rumus**: R²adj = 1 - [(1 - R²)(n - 1)] / (n - k - 1)\n",
        "- **Keunggulan**: Mempertimbangkan kompleksitas model\n",
        "- **Interpretasi**: Lebih akurat untuk perbandingan model\n",
        "\n",
        "#### 4.1.3 Multiple R\n",
        "- **Definisi**: Korelasi antara nilai aktual dan prediksi\n",
        "- **Rumus**: R = √(R²)\n",
        "- **Interpretasi**: Kekuatan hubungan linear\n",
        "- **Aplikasi**: Ukuran korelasi model\n",
        "\n",
        "### 4.2 Error Measures\n",
        "\n",
        "#### 4.2.1 Mean Squared Error (MSE)\n",
        "- **Definisi**: Rata-rata kuadrat error\n",
        "- **Rumus**: MSE = Σ(Yi - Ŷi)² / n\n",
        "- **Unit**: Kuadrat unit Y\n",
        "- **Interpretasi**: Semakin kecil semakin baik\n",
        "\n",
        "#### 4.2.2 Root Mean Squared Error (RMSE)\n",
        "- **Definisi**: Akar kuadrat MSE\n",
        "- **Rumus**: RMSE = √(MSE)\n",
        "- **Unit**: Sama dengan unit Y\n",
        "- **Interpretasi**: Rata-rata error prediksi\n",
        "\n",
        "#### 4.2.3 Mean Absolute Error (MAE)\n",
        "- **Definisi**: Rata-rata absolute error\n",
        "- **Rumus**: MAE = Σ|Yi - Ŷi| / n\n",
        "- **Unit**: Sama dengan unit Y\n",
        "- **Interpretasi**: Rata-rata absolute error\n",
        "\n",
        "#### 4.2.4 Mean Absolute Percentage Error (MAPE)\n",
        "- **Definisi**: Rata-rata persentase error\n",
        "- **Rumus**: MAPE = (100/n) × Σ|Yi - Ŷi| / |Yi|\n",
        "- **Unit**: Persentase\n",
        "- **Interpretasi**: Persentase error rata-rata\n",
        "\n",
        "### 4.3 Information Criteria\n",
        "\n",
        "#### 4.3.1 Akaike Information Criterion (AIC)\n",
        "- **Definisi**: Balance antara goodness of fit dan kompleksitas\n",
        "- **Rumus**: AIC = 2k - 2ln(L) = n × ln(MSE) + 2k\n",
        "- **Prinsip**: Semakin kecil semakin baik\n",
        "- **Aplikasi**: Model selection\n",
        "\n",
        "#### 4.3.2 Bayesian Information Criterion (BIC)\n",
        "- **Definisi**: Lebih konservatif daripada AIC\n",
        "- **Rumus**: BIC = k × ln(n) - 2ln(L) = n × ln(MSE) + k × ln(n)\n",
        "- **Prinsip**: Semakin kecil semakin baik\n",
        "- **Keunggulan**: Mempertimbangkan sample size\n",
        "\n",
        "#### 4.3.3 Corrected AIC (AICc)\n",
        "- **Definisi**: Koreksi AIC untuk sample kecil\n",
        "- **Rumus**: AICc = AIC + 2k(k+1)/(n-k-1)\n",
        "- **Aplikasi**: Sample size kecil (n/k < 40)\n",
        "- **Interpretasi**: Lebih akurat untuk sample kecil\n",
        "\n",
        "### 4.4 Cross-Validation\n",
        "\n",
        "#### 4.4.1 k-Fold Cross-Validation\n",
        "- **Prinsip**: Bagi data menjadi k subset\n",
        "- **Proses**: Train pada k-1 subset, test pada 1 subset\n",
        "- **Kriteria**: k = 5 atau 10\n",
        "- **Keunggulan**: Mengurangi bias, estimasi stabil\n",
        "\n",
        "#### 4.4.2 Leave-One-Out Cross-Validation (LOOCV)\n",
        "- **Prinsip**: Train pada n-1 observasi, test pada 1 observasi\n",
        "- **Proses**: Ulangi untuk semua observasi\n",
        "- **Keunggulan**: Menggunakan semua data\n",
        "- **Kekurangan**: Computationally expensive\n",
        "\n",
        "#### 4.4.3 Holdout Validation\n",
        "- **Prinsip**: Bagi data menjadi training dan testing\n",
        "- **Proporsi**: 70-80% training, 20-30% testing\n",
        "- **Keunggulan**: Sederhana, cepat\n",
        "- **Kekurangan**: Dapat bias\n",
        "\n",
        "### 4.5 Residual Analysis\n",
        "\n",
        "#### 4.5.1 Residual Plots\n",
        "- **Residuals vs Fitted**: Cek homoscedasticity\n",
        "- **Residuals vs Predictors**: Cek linearity\n",
        "- **Q-Q Plot**: Cek normalitas\n",
        "- **Leverage Plot**: Cek outliers\n",
        "\n",
        "#### 4.5.2 Residual Statistics\n",
        "- **Mean Residual**: Harus mendekati 0\n",
        "- **Standard Deviation**: Ukuran variabilitas\n",
        "- **Skewness**: Asimetri distribusi\n",
        "- **Kurtosis**: Ketajaman distribusi\n",
        "\n",
        "### 4.6 Outlier Detection\n",
        "\n",
        "#### 4.6.1 Studentized Residuals\n",
        "- **Definisi**: Residuals yang distandarisasi\n",
        "- **Rumus**: rᵢ = eᵢ / (s × √(1 - hᵢᵢ))\n",
        "- **Threshold**: |rᵢ| > 2 atau 3\n",
        "- **Interpretasi**: Outlier jika |rᵢ| > threshold\n",
        "\n",
        "#### 4.6.2 Cook's Distance\n",
        "- **Definisi**: Pengaruh observasi pada model\n",
        "- **Rumus**: Dᵢ = (eᵢ² / (k × MSE)) × (hᵢᵢ / (1 - hᵢᵢ)²)\n",
        "- **Threshold**: Dᵢ > 4/n\n",
        "- **Interpretasi**: Influential jika Dᵢ > threshold\n",
        "\n",
        "#### 4.6.3 Leverage\n",
        "- **Definisi**: Pengaruh observasi pada prediksi\n",
        "- **Rumus**: hᵢᵢ = Xᵢ(X'X)⁻¹Xᵢ'\n",
        "- **Threshold**: hᵢᵢ > 2(k+1)/n\n",
        "- **Interpretasi**: High leverage jika hᵢᵢ > threshold\n",
        "\n",
        "### 4.7 Model Comparison\n",
        "\n",
        "#### 4.7.1 Nested Models\n",
        "- **Definisi**: Model yang satu subset dari yang lain\n",
        "- **Testing**: F-test untuk perbedaan R²\n",
        "- **Rumus**: F = [(R²₁ - R²₀) / (k₁ - k₀)] / [(1 - R²₁) / (n - k₁ - 1)]\n",
        "- **Interpretasi**: Model yang lebih kompleks signifikan lebih baik\n",
        "\n",
        "#### 4.7.2 Non-nested Models\n",
        "- **Definisi**: Model yang tidak subset satu sama lain\n",
        "- **Testing**: AIC, BIC, atau cross-validation\n",
        "- **Prinsip**: Pilih model dengan kriteria terbaik\n",
        "- **Aplikasi**: Model dengan variabel berbeda\n",
        "\n",
        "### 4.8 Prediction Intervals\n",
        "\n",
        "#### 4.8.1 Confidence Interval\n",
        "- **Definisi**: Interval untuk mean prediksi\n",
        "- **Rumus**: CI = Ŷ ± t(α/2, n-k-1) × SE(Ŷ)\n",
        "- **Interpretasi**: Interval untuk rata-rata Y\n",
        "- **Aplikasi**: Estimasi parameter\n",
        "\n",
        "#### 4.8.2 Prediction Interval\n",
        "- **Definisi**: Interval untuk prediksi individual\n",
        "- **Rumus**: PI = Ŷ ± t(α/2, n-k-1) × SE(Ŷ + ε)\n",
        "- **Interpretasi**: Interval untuk Y individual\n",
        "- **Aplikasi**: Prediksi individual\n",
        "\n",
        "### 4.9 Model Validation\n",
        "\n",
        "#### 4.9.1 In-sample Validation\n",
        "- **Definisi**: Validasi pada data yang sama\n",
        "- **Ukuran**: R², RMSE, MAE\n",
        "- **Keterbatasan**: Dapat overfit\n",
        "- **Aplikasi**: Initial assessment\n",
        "\n",
        "#### 4.9.2 Out-of-sample Validation\n",
        "- **Definisi**: Validasi pada data baru\n",
        "- **Ukuran**: R², RMSE, MAE\n",
        "- **Keunggulan**: Estimasi yang lebih akurat\n",
        "- **Aplikasi**: Final assessment\n",
        "\n",
        "### 4.10 Practical Guidelines\n",
        "\n",
        "#### 4.10.1 Model Selection\n",
        "- **Multiple Criteria**: Gunakan beberapa ukuran\n",
        "- **Cross-validation**: Validasi dengan data independen\n",
        "- **Domain Knowledge**: Pertimbangkan teori\n",
        "- **Simplicity**: Pilih model yang sederhana\n",
        "\n",
        "#### 4.10.2 Reporting Results\n",
        "- **Transparency**: Laporkan semua ukuran\n",
        "- **Confidence**: Gunakan confidence interval\n",
        "- **Limitations**: Diskusikan keterbatasan\n",
        "- **Recommendations**: Berikan rekomendasi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Multikolinearitas (Multicollinearity)\n",
        "\n",
        "### 5.1 Pengertian Multikolinearitas\n",
        "\n",
        "#### 5.1.1 Definisi\n",
        "- **Multikolinearitas**: Korelasi tinggi antar variabel independen\n",
        "- **Perfect Multicollinearity**: Korelasi sempurna (r = 1)\n",
        "- **Near Multicollinearity**: Korelasi tinggi (r > 0.8)\n",
        "- **Problem**: Sulit mengisolasi efek individual variabel\n",
        "\n",
        "#### 5.1.2 Jenis Multikolinearitas\n",
        "- **Structural**: Variabel yang secara alami berkorelasi\n",
        "- **Data-based**: Korelasi karena sampling\n",
        "- **Dummy Variable Trap**: Multikolinearitas karena dummy variables\n",
        "- **Polynomial**: Multikolinearitas karena polynomial terms\n",
        "\n",
        "### 5.2 Dampak Multikolinearitas\n",
        "\n",
        "#### 5.2.1 Dampak pada Koefisien\n",
        "- **Variance Inflation**: Meningkatkan varians koefisien\n",
        "- **Instability**: Koefisien tidak stabil\n",
        "- **Significance**: Menurunkan signifikansi statistik\n",
        "- **Interpretation**: Sulit menginterpretasikan koefisien\n",
        "\n",
        "#### 5.2.2 Dampak pada Model\n",
        "- **R²**: Tidak terpengaruh\n",
        "- **F-test**: Tidak terpengaruh\n",
        "- **Prediction**: Tidak terpengaruh\n",
        "- **Confidence Interval**: Lebih lebar\n",
        "\n",
        "#### 5.2.3 Dampak pada Estimasi\n",
        "- **Bias**: Koefisien tetap unbiased\n",
        "- **Efficiency**: Koefisien kurang efficient\n",
        "- **Consistency**: Koefisien tetap consistent\n",
        "- **Asymptotic**: Tidak terpengaruh secara asimtotik\n",
        "\n",
        "### 5.3 Deteksi Multikolinearitas\n",
        "\n",
        "#### 5.3.1 Correlation Matrix\n",
        "- **Method**: Hitung korelasi antar variabel independen\n",
        "- **Threshold**: |r| > 0.8 atau 0.9\n",
        "- **Keunggulan**: Sederhana, mudah diinterpretasikan\n",
        "- **Kekurangan**: Hanya mendeteksi pairwise correlation\n",
        "\n",
        "#### 5.3.2 Variance Inflation Factor (VIF)\n",
        "- **Definisi**: VIFᵢ = 1 / (1 - R²ᵢ)\n",
        "- **Interpretasi**: VIF > 10 menunjukkan multikolinearitas\n",
        "- **Threshold**: VIF > 5 (moderate), VIF > 10 (high)\n",
        "- **Keunggulan**: Mendeteksi multikolinearitas multiple\n",
        "\n",
        "#### 5.3.3 Tolerance\n",
        "- **Definisi**: Toleranceᵢ = 1 - R²ᵢ = 1 / VIFᵢ\n",
        "- **Interpretasi**: Tolerance < 0.1 menunjukkan multikolinearitas\n",
        "- **Threshold**: Tolerance < 0.2 (moderate), Tolerance < 0.1 (high)\n",
        "- **Keunggulan**: Interpretasi yang lebih intuitif\n",
        "\n",
        "#### 5.3.4 Condition Index\n",
        "- **Definisi**: CI = √(λmax / λmin)\n",
        "- **Interpretasi**: CI > 30 menunjukkan multikolinearitas\n",
        "- **Threshold**: CI > 10 (moderate), CI > 30 (high)\n",
        "- **Keunggulan**: Mendeteksi multikolinearitas kompleks\n",
        "\n",
        "### 5.4 Solusi Multikolinearitas\n",
        "\n",
        "#### 5.4.1 Data Collection\n",
        "- **More Data**: Kumpulkan data lebih banyak\n",
        "- **Different Sample**: Gunakan sample yang berbeda\n",
        "- **Experimental Design**: Desain eksperimen yang tepat\n",
        "- **Randomization**: Randomisasi variabel\n",
        "\n",
        "#### 5.4.2 Variable Selection\n",
        "- **Remove Variables**: Hapus variabel yang redundan\n",
        "- **Combine Variables**: Gabungkan variabel yang berkorelasi\n",
        "- **Principal Components**: Gunakan PCA\n",
        "- **Factor Analysis**: Gunakan analisis faktor\n",
        "\n",
        "#### 5.4.3 Regularization\n",
        "- **Ridge Regression**: Menyusutkan koefisien\n",
        "- **Lasso Regression**: Menyusutkan koefisien ke 0\n",
        "- **Elastic Net**: Kombinasi Ridge dan Lasso\n",
        "- **Bayesian Methods**: Metode Bayesian\n",
        "\n",
        "#### 5.4.4 Transformation\n",
        "- **Centering**: Kurangi mean variabel\n",
        "- **Scaling**: Bagi dengan standar deviasi\n",
        "- **Log Transformation**: Transformasi log\n",
        "- **Box-Cox**: Transformasi Box-Cox\n",
        "\n",
        "### 5.5 Ridge Regression\n",
        "\n",
        "#### 5.5.1 Prinsip\n",
        "- **Penalty**: Menambahkan penalty pada sum of squared coefficients\n",
        "- **Rumus**: min(SSR + λΣβᵢ²)\n",
        "- **Effect**: Menyusutkan koefisien menuju 0\n",
        "- **Bias-Variance**: Trade-off bias dan variance\n",
        "\n",
        "#### 5.5.2 Parameter Tuning\n",
        "- **Lambda (α)**: Parameter regularisasi\n",
        "- **Cross-validation**: Pilih lambda optimal\n",
        "- **Grid Search**: Cari lambda terbaik\n",
        "- **Validation Curve**: Plot performa vs lambda\n",
        "\n",
        "#### 5.5.3 Interpretasi\n",
        "- **Coefficients**: Koefisien yang disusutkan\n",
        "- **Prediction**: Prediksi yang lebih stabil\n",
        "- **Variance**: Mengurangi varians koefisien\n",
        "- **Bias**: Menambah bias koefisien\n",
        "\n",
        "### 5.6 Lasso Regression\n",
        "\n",
        "#### 5.6.1 Prinsip\n",
        "- **Penalty**: Menambahkan penalty pada sum of absolute coefficients\n",
        "- **Rumus**: min(SSR + λΣ|βᵢ|)\n",
        "- **Effect**: Menyusutkan koefisien ke 0\n",
        "- **Feature Selection**: Otomatis melakukan feature selection\n",
        "\n",
        "#### 5.6.2 Parameter Tuning\n",
        "- **Lambda (α)**: Parameter regularisasi\n",
        "- **Cross-validation**: Pilih lambda optimal\n",
        "- **Path Algorithm**: Hitung path koefisien\n",
        "- **Validation Curve**: Plot performa vs lambda\n",
        "\n",
        "#### 5.6.3 Interpretasi\n",
        "- **Coefficients**: Koefisien yang disusutkan\n",
        "- **Feature Selection**: Variabel yang dipilih\n",
        "- **Sparsity**: Model yang sparse\n",
        "- **Interpretability**: Model yang mudah diinterpretasikan\n",
        "\n",
        "### 5.7 Elastic Net\n",
        "\n",
        "#### 5.7.1 Prinsip\n",
        "- **Penalty**: Kombinasi L1 dan L2 penalty\n",
        "- **Rumus**: min(SSR + λ₁Σ|βᵢ| + λ₂Σβᵢ²)\n",
        "- **Effect**: Kombinasi feature selection dan shrinkage\n",
        "- **Balance**: Balance antara Ridge dan Lasso\n",
        "\n",
        "#### 5.7.2 Parameter Tuning\n",
        "- **Alpha**: Parameter regularisasi total\n",
        "- **L1 Ratio**: Proporsi L1 penalty\n",
        "- **Cross-validation**: Pilih parameter optimal\n",
        "- **Grid Search**: Cari parameter terbaik\n",
        "\n",
        "#### 5.7.3 Interpretasi\n",
        "- **Coefficients**: Koefisien yang disusutkan\n",
        "- **Feature Selection**: Variabel yang dipilih\n",
        "- **Stability**: Lebih stabil daripada Lasso\n",
        "- **Grouping**: Menangani variabel yang berkorelasi\n",
        "\n",
        "### 5.8 Principal Component Regression (PCR)\n",
        "\n",
        "#### 5.8.1 Prinsip\n",
        "- **PCA**: Transformasi variabel menjadi komponen utama\n",
        "- **Regression**: Regresi pada komponen utama\n",
        "- **Dimensionality**: Mengurangi dimensi\n",
        "- **Multicollinearity**: Menghilangkan multikolinearitas\n",
        "\n",
        "#### 5.8.2 Implementasi\n",
        "- **Standardization**: Standarisasi variabel\n",
        "- **PCA**: Hitung komponen utama\n",
        "- **Selection**: Pilih komponen yang signifikan\n",
        "- **Regression**: Regresi pada komponen terpilih\n",
        "\n",
        "#### 5.8.3 Interpretasi\n",
        "- **Components**: Komponen utama yang tidak berkorelasi\n",
        "- **Variance**: Proporsi varians yang dijelaskan\n",
        "- **Coefficients**: Koefisien pada komponen utama\n",
        "- **Prediction**: Prediksi yang stabil\n",
        "\n",
        "### 5.9 Partial Least Squares (PLS)\n",
        "\n",
        "#### 5.9.1 Prinsip\n",
        "- **Supervised**: Menggunakan informasi Y\n",
        "- **Components**: Komponen yang memaksimalkan kovarians\n",
        "- **Regression**: Regresi pada komponen PLS\n",
        "- **Multicollinearity**: Menangani multikolinearitas\n",
        "\n",
        "#### 5.9.2 Implementasi\n",
        "- **Standardization**: Standarisasi variabel\n",
        "- **PLS**: Hitung komponen PLS\n",
        "- **Selection**: Pilih komponen yang signifikan\n",
        "- **Regression**: Regresi pada komponen PLS\n",
        "\n",
        "#### 5.9.3 Interpretasi\n",
        "- **Components**: Komponen PLS yang tidak berkorelasi\n",
        "- **Variance**: Proporsi varians yang dijelaskan\n",
        "- **Coefficients**: Koefisien pada komponen PLS\n",
        "- **Prediction**: Prediksi yang optimal\n",
        "\n",
        "### 5.10 Practical Guidelines\n",
        "\n",
        "#### 5.10.1 Deteksi\n",
        "- **Multiple Methods**: Gunakan beberapa metode deteksi\n",
        "- **Threshold**: Gunakan threshold yang konsisten\n",
        "- **Context**: Pertimbangkan konteks penelitian\n",
        "- **Domain Knowledge**: Gunakan pengetahuan domain\n",
        "\n",
        "#### 5.10.2 Solusi\n",
        "- **Data First**: Coba solusi data terlebih dahulu\n",
        "- **Regularization**: Gunakan regularisasi jika perlu\n",
        "- **Validation**: Validasi solusi dengan data independen\n",
        "- **Interpretation**: Pertimbangkan interpretabilitas\n",
        "\n",
        "#### 5.10.3 Reporting\n",
        "- **Transparency**: Laporkan deteksi multikolinearitas\n",
        "- **Solutions**: Jelaskan solusi yang digunakan\n",
        "- **Limitations**: Diskusikan keterbatasan\n",
        "- **Recommendations**: Berikan rekomendasi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrasi Interpretasi Koefisien dan Evaluasi Model\n",
        "print(\"=== DEMONSTRASI INTERPRETASI KOEFISIEN DAN EVALUASI MODEL ===\")\n",
        "\n",
        "# Data untuk demonstrasi interpretasi koefisien dan evaluasi model\n",
        "np.random.seed(42)\n",
        "\n",
        "# 1. Data dengan variabel yang berbeda skala\n",
        "print(\"1. DATA DENGAN VARIABEL BERBEDA SKALA:\")\n",
        "\n",
        "# Simulasi data\n",
        "n = 100\n",
        "X1 = np.random.normal(50, 15, n)  # Skala 0-100\n",
        "X2 = np.random.normal(5, 2, n)    # Skala 0-10\n",
        "X3 = np.random.normal(1000, 200, n)  # Skala 0-2000\n",
        "\n",
        "# Variabel dependen\n",
        "Y = 2 * X1 + 10 * X2 + 0.001 * X3 + 50 + np.random.normal(0, 10, n)\n",
        "\n",
        "# Buat DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Y': Y,\n",
        "    'X1': X1,\n",
        "    'X2': X2,\n",
        "    'X3': X3\n",
        "})\n",
        "\n",
        "print(\"Data untuk Interpretasi Koefisien:\")\n",
        "print(df.head())\n",
        "print(f\"\\nStatistik deskriptif:\")\n",
        "print(df.describe())\n",
        "\n",
        "# 2. Regresi Multiple dengan sklearn\n",
        "print(\"\\n2. REGRESI MULTIPLE:\")\n",
        "\n",
        "# Siapkan data\n",
        "X = df[['X1', 'X2', 'X3']]\n",
        "y = df['Y']\n",
        "\n",
        "# Buat model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Prediksi\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Koefisien\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "\n",
        "print(f\"Intercept: {intercept:.4f}\")\n",
        "print(f\"Koefisien X1: {coefficients[0]:.4f}\")\n",
        "print(f\"Koefisien X2: {coefficients[1]:.4f}\")\n",
        "print(f\"Koefisien X3: {coefficients[2]:.4f}\")\n",
        "\n",
        "# 3. Standardized Coefficients\n",
        "print(\"\\n3. STANDARDIZED COEFFICIENTS:\")\n",
        "\n",
        "# Hitung standardized coefficients\n",
        "y_std = np.std(y)\n",
        "x1_std = np.std(X1)\n",
        "x2_std = np.std(X2)\n",
        "x3_std = np.std(X3)\n",
        "\n",
        "beta1_std = coefficients[0] * (x1_std / y_std)\n",
        "beta2_std = coefficients[1] * (x2_std / y_std)\n",
        "beta3_std = coefficients[2] * (x3_std / y_std)\n",
        "\n",
        "print(f\"Standardized coefficient X1: {beta1_std:.4f}\")\n",
        "print(f\"Standardized coefficient X2: {beta2_std:.4f}\")\n",
        "print(f\"Standardized coefficient X3: {beta3_std:.4f}\")\n",
        "\n",
        "# Interpretasi standardized coefficients\n",
        "print(\"\\nInterpretasi Standardized Coefficients:\")\n",
        "print(f\"  - X1: Perubahan 1 SD X1 mengubah Y sebesar {beta1_std:.4f} SD\")\n",
        "print(f\"  - X2: Perubahan 1 SD X2 mengubah Y sebesar {beta2_std:.4f} SD\")\n",
        "print(f\"  - X3: Perubahan 1 SD X3 mengubah Y sebesar {beta3_std:.4f} SD\")\n",
        "\n",
        "# 4. Confidence Intervals\n",
        "print(\"\\n4. CONFIDENCE INTERVALS:\")\n",
        "\n",
        "# Hitung standard errors (approximation)\n",
        "mse = np.sum((y - y_pred)**2) / (n - len(coefficients) - 1)\n",
        "x_matrix = np.column_stack([np.ones(n), X1, X2, X3])\n",
        "xtx_inv = np.linalg.inv(x_matrix.T @ x_matrix)\n",
        "se_coeffs = np.sqrt(np.diag(xtx_inv) * mse)\n",
        "\n",
        "# Confidence intervals\n",
        "alpha = 0.05\n",
        "t_critical = stats.t.ppf(1 - alpha/2, n - len(coefficients) - 1)\n",
        "\n",
        "ci_intercept = [intercept - t_critical * se_coeffs[0], intercept + t_critical * se_coeffs[0]]\n",
        "ci_x1 = [coefficients[0] - t_critical * se_coeffs[1], coefficients[0] + t_critical * se_coeffs[1]]\n",
        "ci_x2 = [coefficients[1] - t_critical * se_coeffs[2], coefficients[1] + t_critical * se_coeffs[2]]\n",
        "ci_x3 = [coefficients[2] - t_critical * se_coeffs[3], coefficients[2] + t_critical * se_coeffs[3]]\n",
        "\n",
        "print(f\"95% Confidence Intervals:\")\n",
        "print(f\"  Intercept: [{ci_intercept[0]:.4f}, {ci_intercept[1]:.4f}]\")\n",
        "print(f\"  X1: [{ci_x1[0]:.4f}, {ci_x1[1]:.4f}]\")\n",
        "print(f\"  X2: [{ci_x2[0]:.4f}, {ci_x2[1]:.4f}]\")\n",
        "print(f\"  X3: [{ci_x3[0]:.4f}, {ci_x3[1]:.4f}]\")\n",
        "\n",
        "# 5. Model Evaluation\n",
        "print(\"\\n5. MODEL EVALUATION:\")\n",
        "\n",
        "# R-squared\n",
        "r2 = r2_score(y, y_pred)\n",
        "print(f\"R-squared: {r2:.4f}\")\n",
        "\n",
        "# Adjusted R-squared\n",
        "k = len(coefficients)\n",
        "adj_r2 = 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
        "print(f\"Adjusted R-squared: {adj_r2:.4f}\")\n",
        "\n",
        "# RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "# MAE\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "\n",
        "# MAPE\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "print(f\"MAPE: {mape:.4f}%\")\n",
        "\n",
        "# 6. Information Criteria\n",
        "print(\"\\n6. INFORMATION CRITERIA:\")\n",
        "\n",
        "# AIC\n",
        "aic = n * np.log(mse) + 2 * (k + 1)\n",
        "print(f\"AIC: {aic:.4f}\")\n",
        "\n",
        "# BIC\n",
        "bic = n * np.log(mse) + (k + 1) * np.log(n)\n",
        "print(f\"BIC: {bic:.4f}\")\n",
        "\n",
        "# AICc\n",
        "aicc = aic + 2 * (k + 1) * (k + 2) / (n - k - 2)\n",
        "print(f\"AICc: {aicc:.4f}\")\n",
        "\n",
        "# 7. Residual Analysis\n",
        "print(\"\\n7. RESIDUAL ANALYSIS:\")\n",
        "\n",
        "# Residuals\n",
        "residuals = y - y_pred\n",
        "\n",
        "# Residual statistics\n",
        "mean_residual = np.mean(residuals)\n",
        "std_residual = np.std(residuals, ddof=1)\n",
        "skewness = stats.skew(residuals)\n",
        "kurtosis = stats.kurtosis(residuals)\n",
        "\n",
        "print(f\"Mean Residual: {mean_residual:.4f}\")\n",
        "print(f\"Std Residual: {std_residual:.4f}\")\n",
        "print(f\"Skewness: {skewness:.4f}\")\n",
        "print(f\"Kurtosis: {kurtosis:.4f}\")\n",
        "\n",
        "# 8. Outlier Detection\n",
        "print(\"\\n8. OUTLIER DETECTION:\")\n",
        "\n",
        "# Studentized residuals\n",
        "mse_residual = np.sum(residuals**2) / (n - k - 1)\n",
        "h_matrix = x_matrix @ xtx_inv @ x_matrix.T\n",
        "h_diag = np.diag(h_matrix)\n",
        "studentized_residuals = residuals / (np.sqrt(mse_residual) * np.sqrt(1 - h_diag))\n",
        "\n",
        "# Cook's distance\n",
        "cooks_d = (residuals**2 / (k * mse_residual)) * (h_diag / (1 - h_diag)**2)\n",
        "\n",
        "# Leverage\n",
        "leverage = h_diag\n",
        "\n",
        "# Outlier detection\n",
        "outliers_studentized = np.abs(studentized_residuals) > 2\n",
        "outliers_cooks = cooks_d > 4/n\n",
        "outliers_leverage = leverage > 2*(k+1)/n\n",
        "\n",
        "print(f\"Outliers (Studentized |r| > 2): {np.sum(outliers_studentized)}\")\n",
        "print(f\"Outliers (Cook's D > 4/n): {np.sum(outliers_cooks)}\")\n",
        "print(f\"Outliers (Leverage > 2(k+1)/n): {np.sum(outliers_leverage)}\")\n",
        "\n",
        "# 9. Cross-Validation\n",
        "print(\"\\n9. CROSS-VALIDATION:\")\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# K-Fold Cross-Validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(LinearRegression(), X, y, cv=kfold, scoring='r2')\n",
        "\n",
        "print(f\"5-Fold CV R²: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "# 10. Visualisasi Interpretasi Koefisien dan Evaluasi Model\n",
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "# Plot 1: Koefisien asli vs standardized\n",
        "plt.subplot(3, 4, 1)\n",
        "variables = ['X1', 'X2', 'X3']\n",
        "coeffs_original = coefficients\n",
        "coeffs_std = [beta1_std, beta2_std, beta3_std]\n",
        "\n",
        "x_pos = np.arange(len(variables))\n",
        "width = 0.35\n",
        "\n",
        "plt.bar(x_pos - width/2, coeffs_original, width, label='Original', alpha=0.7)\n",
        "plt.bar(x_pos + width/2, coeffs_std, width, label='Standardized', alpha=0.7)\n",
        "plt.xlabel('Variables')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.title('Original vs Standardized Coefficients')\n",
        "plt.xticks(x_pos, variables)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Confidence intervals\n",
        "plt.subplot(3, 4, 2)\n",
        "coeffs = [intercept] + list(coefficients)\n",
        "ci_lower = [ci_intercept[0]] + [ci_x1[0], ci_x2[0], ci_x3[0]]\n",
        "ci_upper = [ci_intercept[1]] + [ci_x1[1], ci_x2[1], ci_x3[1]]\n",
        "variables_ci = ['Intercept', 'X1', 'X2', 'X3']\n",
        "\n",
        "plt.errorbar(variables_ci, coeffs, yerr=[np.array(coeffs) - np.array(ci_lower), \n",
        "                                         np.array(ci_upper) - np.array(coeffs)], \n",
        "             fmt='o', capsize=5, capthick=2)\n",
        "plt.xlabel('Variables')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.title('Coefficients with 95% CI')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Model evaluation metrics\n",
        "plt.subplot(3, 4, 3)\n",
        "metrics = ['R²', 'Adj R²', 'RMSE', 'MAE', 'MAPE']\n",
        "values = [r2, adj_r2, rmse, mae, mape/100]  # Normalize MAPE\n",
        "colors = ['blue', 'green', 'red', 'orange', 'purple']\n",
        "\n",
        "plt.bar(metrics, values, color=colors, alpha=0.7)\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Model Evaluation Metrics')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Information criteria\n",
        "plt.subplot(3, 4, 4)\n",
        "criteria = ['AIC', 'BIC', 'AICc']\n",
        "values_criteria = [aic, bic, aicc]\n",
        "\n",
        "plt.bar(criteria, values_criteria, color=['blue', 'green', 'red'], alpha=0.7)\n",
        "plt.xlabel('Criteria')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Information Criteria')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 5: Residuals vs Fitted\n",
        "plt.subplot(3, 4, 5)\n",
        "plt.scatter(y_pred, residuals, alpha=0.7, color='blue')\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel('Fitted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals vs Fitted')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 6: Q-Q plot residuals\n",
        "plt.subplot(3, 4, 6)\n",
        "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
        "plt.title('Q-Q Plot Residuals')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 7: Studentized residuals\n",
        "plt.subplot(3, 4, 7)\n",
        "plt.scatter(y_pred, studentized_residuals, alpha=0.7, color='blue')\n",
        "plt.axhline(2, color='red', linestyle='--', label='Threshold = 2')\n",
        "plt.axhline(-2, color='red', linestyle='--')\n",
        "plt.xlabel('Fitted Values')\n",
        "plt.ylabel('Studentized Residuals')\n",
        "plt.title('Studentized Residuals')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 8: Cook's distance\n",
        "plt.subplot(3, 4, 8)\n",
        "plt.scatter(range(len(cooks_d)), cooks_d, alpha=0.7, color='green')\n",
        "plt.axhline(4/n, color='red', linestyle='--', label=f'Threshold = {4/n:.3f}')\n",
        "plt.xlabel('Observation')\n",
        "plt.ylabel(\"Cook's Distance\")\n",
        "plt.title(\"Cook's Distance\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 9: Leverage\n",
        "plt.subplot(3, 4, 9)\n",
        "plt.scatter(range(len(leverage)), leverage, alpha=0.7, color='orange')\n",
        "plt.axhline(2*(k+1)/n, color='red', linestyle='--', label=f'Threshold = {2*(k+1)/n:.3f}')\n",
        "plt.xlabel('Observation')\n",
        "plt.ylabel('Leverage')\n",
        "plt.title('Leverage')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 10: Predicted vs Actual\n",
        "plt.subplot(3, 4, 10)\n",
        "plt.scatter(y, y_pred, alpha=0.7, color='blue')\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', linewidth=2)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Predicted vs Actual')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 11: Cross-validation scores\n",
        "plt.subplot(3, 4, 11)\n",
        "plt.bar(range(1, 6), cv_scores, alpha=0.7, color='purple')\n",
        "plt.axhline(cv_scores.mean(), color='red', linestyle='--', label=f'Mean = {cv_scores.mean():.3f}')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('R² Score')\n",
        "plt.title('Cross-Validation Scores')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 12: Summary\n",
        "plt.subplot(3, 4, 12)\n",
        "plt.axis('off')\n",
        "summary_text = f\"\"\"\n",
        "INTERPRETASI KOEFISIEN & EVALUASI MODEL\n",
        "\n",
        "Koefisien Asli:\n",
        "X1: {coefficients[0]:.4f}\n",
        "X2: {coefficients[1]:.4f}\n",
        "X3: {coefficients[2]:.4f}\n",
        "\n",
        "Koefisien Standardized:\n",
        "X1: {beta1_std:.4f}\n",
        "X2: {beta2_std:.4f}\n",
        "X3: {beta3_std:.4f}\n",
        "\n",
        "Model Evaluation:\n",
        "R² = {r2:.4f}\n",
        "Adj R² = {adj_r2:.4f}\n",
        "RMSE = {rmse:.4f}\n",
        "MAE = {mae:.4f}\n",
        "MAPE = {mape:.2f}%\n",
        "\n",
        "Information Criteria:\n",
        "AIC = {aic:.2f}\n",
        "BIC = {bic:.2f}\n",
        "AICc = {aicc:.2f}\n",
        "\n",
        "Cross-Validation:\n",
        "CV R² = {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\n",
        "\n",
        "Outliers:\n",
        "Studentized: {np.sum(outliers_studentized)}\n",
        "Cook's D: {np.sum(outliers_cooks)}\n",
        "Leverage: {np.sum(outliers_leverage)}\n",
        "\"\"\"\n",
        "plt.text(0.1, 0.9, summary_text, transform=plt.gca().transAxes, fontsize=8, \n",
        "         verticalalignment='top', fontfamily='monospace')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 11. Interpretasi Hasil\n",
        "print(\"\\n11. INTERPRETASI HASIL:\")\n",
        "\n",
        "print(f\"\\nKoefisien Regresi:\")\n",
        "print(f\"  - X1: {coefficients[0]:.4f}\")\n",
        "print(f\"    Interpretasi: Mengontrol X2 dan X3, setiap peningkatan 1 unit X1 mengubah Y sebesar {coefficients[0]:.4f} unit\")\n",
        "print(f\"  - X2: {coefficients[1]:.4f}\")\n",
        "print(f\"    Interpretasi: Mengontrol X1 dan X3, setiap peningkatan 1 unit X2 mengubah Y sebesar {coefficients[1]:.4f} unit\")\n",
        "print(f\"  - X3: {coefficients[2]:.4f}\")\n",
        "print(f\"    Interpretasi: Mengontrol X1 dan X2, setiap peningkatan 1 unit X3 mengubah Y sebesar {coefficients[2]:.4f} unit\")\n",
        "\n",
        "print(f\"\\nStandardized Coefficients:\")\n",
        "print(f\"  - X1: {beta1_std:.4f} (pengaruh terkuat)\")\n",
        "print(f\"  - X2: {beta2_std:.4f}\")\n",
        "print(f\"  - X3: {beta3_std:.4f} (pengaruh terlemah)\")\n",
        "\n",
        "print(f\"\\nModel Performance:\")\n",
        "print(f\"  - R²: {r2:.4f} ({r2*100:.1f}% varians Y dijelaskan oleh model)\")\n",
        "print(f\"  - Adjusted R²: {adj_r2:.4f} (R² yang disesuaikan untuk jumlah variabel)\")\n",
        "print(f\"  - RMSE: {rmse:.4f} (Rata-rata error prediksi)\")\n",
        "print(f\"  - MAE: {mae:.4f} (Rata-rata absolute error)\")\n",
        "print(f\"  - MAPE: {mape:.2f}% (Rata-rata persentase error)\")\n",
        "\n",
        "print(f\"\\nModel Quality:\")\n",
        "print(f\"  - AIC: {aic:.2f} (Semakin kecil semakin baik)\")\n",
        "print(f\"  - BIC: {bic:.2f} (Semakin kecil semakin baik)\")\n",
        "print(f\"  - AICc: {aicc:.2f} (Untuk sample kecil)\")\n",
        "\n",
        "print(f\"\\nCross-Validation:\")\n",
        "print(f\"  - CV R²: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
        "print(f\"  - Interpretasi: Model stabil dan generalizable\")\n",
        "\n",
        "print(f\"\\nOutlier Detection:\")\n",
        "print(f\"  - Studentized residuals: {np.sum(outliers_studentized)} outliers\")\n",
        "print(f\"  - Cook's distance: {np.sum(outliers_cooks)} influential points\")\n",
        "print(f\"  - Leverage: {np.sum(outliers_leverage)} high leverage points\")\n",
        "\n",
        "# 12. Kesimpulan dan Rekomendasi\n",
        "print(\"\\n12. KESIMPULAN DAN REKOMENDASI:\")\n",
        "print(\"   - Interpretasi Koefisien: Pertimbangkan skala variabel\")\n",
        "print(\"   - Standardized Coefficients: Untuk perbandingan pengaruh relatif\")\n",
        "print(\"   - Confidence Intervals: Estimasi ketidakpastian parameter\")\n",
        "print(\"   - Model Evaluation: Gunakan multiple metrics\")\n",
        "print(\"   - Information Criteria: Untuk model selection\")\n",
        "print(\"   - Cross-Validation: Untuk validasi model\")\n",
        "print(\"   - Outlier Detection: Identifikasi observasi yang berpengaruh\")\n",
        "print(\"   - Best practice: Kombinasi interpretasi dan evaluasi\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Aplikasi Praktis Regresi Multiple\n",
        "\n",
        "### 8.1 Penelitian Medis\n",
        "\n",
        "#### 8.1.1 Prediksi Risiko Penyakit\n",
        "- **Variabel Dependen**: Risiko penyakit (skor, probabilitas)\n",
        "- **Variabel Independen**: Usia, BMI, tekanan darah, kolesterol, riwayat keluarga\n",
        "- **Contoh**: Model prediksi diabetes berdasarkan faktor risiko\n",
        "- **Interpretasi**: Kontribusi relatif setiap faktor risiko\n",
        "\n",
        "#### 8.1.2 Analisis Efektivitas Pengobatan\n",
        "- **Variabel Dependen**: Respons pengobatan (skor, waktu sembuh)\n",
        "- **Variabel Independen**: Dosis obat, usia, berat badan, jenis kelamin\n",
        "- **Contoh**: Efektivitas antibiotik berdasarkan dosis dan karakteristik pasien\n",
        "- **Interpretasi**: Dosis optimal untuk kelompok pasien tertentu\n",
        "\n",
        "#### 8.1.3 Quality of Life Assessment\n",
        "- **Variabel Dependen**: Skor kualitas hidup\n",
        "- **Variabel Independen**: Gejala, usia, jenis kelamin, status sosial ekonomi\n",
        "- **Contoh**: Faktor yang mempengaruhi kualitas hidup pasien kanker\n",
        "- **Interpretasi**: Faktor protektif dan risiko\n",
        "\n",
        "### 8.2 Penelitian Ekonomi\n",
        "\n",
        "#### 8.2.1 Demand Forecasting\n",
        "- **Variabel Dependen**: Permintaan produk\n",
        "- **Variabel Independen**: Harga, pendapatan, harga produk substitusi, iklan\n",
        "- **Contoh**: Prediksi penjualan smartphone berdasarkan faktor ekonomi\n",
        "- **Interpretasi**: Elastisitas permintaan terhadap berbagai faktor\n",
        "\n",
        "#### 8.2.2 Price Elasticity Analysis\n",
        "- **Variabel Dependen**: Kuantitas yang diminta\n",
        "- **Variabel Independen**: Harga, pendapatan, harga produk lain\n",
        "- **Contoh**: Elastisitas harga minyak terhadap permintaan\n",
        "- **Interpretasi**: Sensitivitas permintaan terhadap perubahan harga\n",
        "\n",
        "#### 8.2.3 Economic Growth Modeling\n",
        "- **Variabel Dependen**: Pertumbuhan ekonomi (GDP growth)\n",
        "- **Variabel Independen**: Investasi, tenaga kerja, teknologi, kebijakan\n",
        "- **Contoh**: Faktor yang mempengaruhi pertumbuhan ekonomi negara\n",
        "- **Interpretasi**: Kontribusi relatif setiap faktor pertumbuhan\n",
        "\n",
        "### 8.3 Penelitian Psikologi\n",
        "\n",
        "#### 8.3.1 Behavior Prediction\n",
        "- **Variabel Dependen**: Perilaku (skor, frekuensi)\n",
        "- **Variabel Independen**: Kepribadian, motivasi, lingkungan, demografi\n",
        "- **Contoh**: Prediksi perilaku konsumen berdasarkan faktor psikologis\n",
        "- **Interpretasi**: Faktor psikologis yang paling berpengaruh\n",
        "\n",
        "#### 8.3.2 Therapy Effectiveness\n",
        "- **Variabel Dependen**: Perbaikan gejala (skor, rating)\n",
        "- **Variabel Independen**: Jenis terapi, durasi, karakteristik pasien\n",
        "- **Contoh**: Efektivitas terapi kognitif-behavioral untuk depresi\n",
        "- **Interpretasi**: Faktor yang mempengaruhi keberhasilan terapi\n",
        "\n",
        "#### 8.3.3 Academic Performance\n",
        "- **Variabel Dependen**: Prestasi akademik (nilai, skor)\n",
        "- **Variabel Independen**: IQ, motivasi, dukungan keluarga, metode belajar\n",
        "- **Contoh**: Faktor yang mempengaruhi prestasi siswa\n",
        "- **Interpretasi**: Faktor yang paling penting untuk sukses akademik\n",
        "\n",
        "### 8.4 Penelitian Bisnis\n",
        "\n",
        "#### 8.4.1 Sales Forecasting\n",
        "- **Variabel Dependen**: Penjualan (volume, revenue)\n",
        "- **Variabel Independen**: Harga, iklan, musim, kompetitor, ekonomi\n",
        "- **Contoh**: Prediksi penjualan produk berdasarkan strategi pemasaran\n",
        "- **Interpretasi**: ROI dari berbagai strategi pemasaran\n",
        "\n",
        "#### 8.4.2 Customer Lifetime Value\n",
        "- **Variabel Dependen**: Nilai pelanggan seumur hidup\n",
        "- **Variabel Independen**: Demografi, perilaku, interaksi, produk\n",
        "- **Contoh**: Prediksi nilai pelanggan berdasarkan karakteristik\n",
        "- **Interpretasi**: Faktor yang meningkatkan nilai pelanggan\n",
        "\n",
        "#### 8.4.3 Employee Performance\n",
        "- **Variabel Dependen**: Performa karyawan (rating, output)\n",
        "- **Variabel Independen**: Pengalaman, pendidikan, pelatihan, motivasi\n",
        "- **Contoh**: Faktor yang mempengaruhi produktivitas karyawan\n",
        "- **Interpretasi**: Faktor yang paling penting untuk performa\n",
        "\n",
        "### 8.5 Penelitian Pendidikan\n",
        "\n",
        "#### 8.5.1 Student Achievement\n",
        "- **Variabel Dependen**: Prestasi siswa (nilai, skor)\n",
        "- **Variabel Independen**: IQ, motivasi, dukungan keluarga, metode mengajar\n",
        "- **Contoh**: Faktor yang mempengaruhi prestasi siswa\n",
        "- **Interpretasi**: Faktor yang paling penting untuk sukses akademik\n",
        "\n",
        "#### 8.5.2 Teacher Effectiveness\n",
        "- **Variabel Dependen**: Efektivitas guru (rating, hasil siswa)\n",
        "- **Variabel Independen**: Pengalaman, pendidikan, pelatihan, motivasi\n",
        "- **Contoh**: Faktor yang mempengaruhi efektivitas mengajar\n",
        "- **Interpretasi**: Faktor yang paling penting untuk efektivitas\n",
        "\n",
        "#### 8.5.3 School Performance\n",
        "- **Variabel Dependen**: Performa sekolah (skor, rating)\n",
        "- **Variabel Independen**: Sumber daya, kepemimpinan, kurikulum, lingkungan\n",
        "- **Contoh**: Faktor yang mempengaruhi performa sekolah\n",
        "- **Interpretasi**: Faktor yang paling penting untuk sukses sekolah\n",
        "\n",
        "### 8.6 Penelitian Teknologi\n",
        "\n",
        "#### 8.6.1 System Performance\n",
        "- **Variabel Dependen**: Performa sistem (waktu, throughput)\n",
        "- **Variabel Independen**: Hardware, software, konfigurasi, beban\n",
        "- **Contoh**: Faktor yang mempengaruhi performa database\n",
        "- **Interpretasi**: Faktor yang paling penting untuk optimasi\n",
        "\n",
        "#### 8.6.2 User Engagement\n",
        "- **Variabel Dependen**: Engagement pengguna (waktu, interaksi)\n",
        "- **Variabel Independen**: Fitur, desain, konten, demografi\n",
        "- **Contoh**: Faktor yang mempengaruhi engagement aplikasi\n",
        "- **Interpretasi**: Faktor yang paling penting untuk retention\n",
        "\n",
        "#### 8.6.3 Software Quality\n",
        "- **Variabel Dependen**: Kualitas software (bug, maintainability)\n",
        "- **Variabel Independen**: Kompleksitas, tim, proses, tools\n",
        "- **Contoh**: Faktor yang mempengaruhi kualitas kode\n",
        "- **Interpretasi**: Faktor yang paling penting untuk kualitas\n",
        "\n",
        "### 8.7 Penelitian Lingkungan\n",
        "\n",
        "#### 8.7.1 Climate Modeling\n",
        "- **Variabel Dependen**: Perubahan iklim (suhu, curah hujan)\n",
        "- **Variabel Independen**: Emisi, deforestasi, urbanisasi, aktivitas manusia\n",
        "- **Contoh**: Faktor yang mempengaruhi perubahan iklim\n",
        "- **Interpretasi**: Kontribusi relatif setiap faktor\n",
        "\n",
        "#### 8.7.2 Pollution Prediction\n",
        "- **Variabel Dependen**: Tingkat polusi (PM2.5, NOx, SOx)\n",
        "- **Variabel Independen**: Emisi, cuaca, lalu lintas, industri\n",
        "- **Contoh**: Prediksi polusi udara berdasarkan faktor lingkungan\n",
        "- **Interpretasi**: Faktor yang paling berpengaruh pada polusi\n",
        "\n",
        "#### 8.7.3 Ecosystem Health\n",
        "- **Variabel Dependen**: Kesehatan ekosistem (biodiversity, productivity)\n",
        "- **Variabel Independen**: Suhu, curah hujan, polusi, aktivitas manusia\n",
        "- **Contoh**: Faktor yang mempengaruhi kesehatan hutan\n",
        "- **Interpretasi**: Faktor yang paling penting untuk konservasi\n",
        "\n",
        "### 8.8 Penelitian Sosial\n",
        "\n",
        "#### 8.8.1 Social Behavior\n",
        "- **Variabel Dependen**: Perilaku sosial (partisipasi, voting)\n",
        "- **Variabel Independen**: Demografi, pendidikan, pendapatan, budaya\n",
        "- **Contoh**: Faktor yang mempengaruhi partisipasi politik\n",
        "- **Interpretasi**: Faktor yang paling penting untuk engagement\n",
        "\n",
        "#### 8.8.2 Policy Impact\n",
        "- **Variabel Dependen**: Dampak kebijakan (outcome, satisfaction)\n",
        "- **Variabel Independen**: Jenis kebijakan, implementasi, konteks\n",
        "- **Contoh**: Efektivitas program bantuan sosial\n",
        "- **Interpretasi**: Faktor yang paling penting untuk keberhasilan\n",
        "\n",
        "#### 8.8.3 Community Development\n",
        "- **Variabel Dependen**: Perkembangan komunitas (indeks, rating)\n",
        "- **Variabel Independen**: Sumber daya, kepemimpinan, partisipasi\n",
        "- **Contoh**: Faktor yang mempengaruhi perkembangan desa\n",
        "- **Interpretasi**: Faktor yang paling penting untuk pembangunan\n",
        "\n",
        "### 8.9 Best Practices untuk Aplikasi\n",
        "\n",
        "#### 8.9.1 Data Quality\n",
        "- **Completeness**: Data lengkap untuk semua variabel\n",
        "- **Accuracy**: Data akurat dan valid\n",
        "- **Consistency**: Data konsisten antar sumber\n",
        "- **Timeliness**: Data terkini dan relevan\n",
        "\n",
        "#### 8.9.2 Model Selection\n",
        "- **Theoretical**: Berdasarkan teori yang ada\n",
        "- **Empirical**: Berdasarkan data yang tersedia\n",
        "- **Practical**: Mempertimbangkan implementasi\n",
        "- **Validation**: Validasi dengan data independen\n",
        "\n",
        "#### 8.9.3 Interpretation\n",
        "- **Context**: Interpretasi dalam konteks penelitian\n",
        "- **Limitations**: Diskusikan keterbatasan model\n",
        "- **Implications**: Jelaskan implikasi praktis\n",
        "- **Recommendations**: Berikan rekomendasi tindakan\n",
        "\n",
        "#### 8.9.4 Communication\n",
        "- **Audience**: Sesuaikan dengan audiens\n",
        "- **Visualization**: Gunakan grafik yang jelas\n",
        "- **Language**: Gunakan bahasa yang mudah dipahami\n",
        "- **Evidence**: Dukung dengan bukti yang kuat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Best Practices dan Troubleshooting\n",
        "\n",
        "### 9.1 Best Practices untuk Regresi Multiple\n",
        "\n",
        "#### 9.1.1 Persiapan Data\n",
        "- **Data Quality**: Pastikan data lengkap, akurat, dan konsisten\n",
        "- **Missing Values**: Handle missing values dengan tepat (imputation, deletion)\n",
        "- **Outliers**: Identifikasi dan handle outliers dengan hati-hati\n",
        "- **Data Types**: Pastikan tipe data sesuai (numeric, categorical)\n",
        "- **Data Distribution**: Periksa distribusi data untuk setiap variabel\n",
        "\n",
        "#### 9.1.2 Pemilihan Variabel\n",
        "- **Theoretical Foundation**: Berdasarkan teori yang ada\n",
        "- **Data Availability**: Pastikan data tersedia untuk semua variabel\n",
        "- **Relevance**: Variabel harus relevan dengan penelitian\n",
        "- **Independence**: Hindari variabel yang terlalu berkorelasi\n",
        "- **Sample Size**: Pastikan sample size cukup untuk jumlah variabel\n",
        "\n",
        "#### 9.1.3 Model Building\n",
        "- **Start Simple**: Mulai dengan model sederhana\n",
        "- **Add Variables**: Tambahkan variabel secara bertahap\n",
        "- **Test Assumptions**: Periksa asumsi model\n",
        "- **Validate Model**: Validasi dengan data independen\n",
        "- **Compare Models**: Bandingkan beberapa model\n",
        "\n",
        "#### 9.1.4 Model Evaluation\n",
        "- **Multiple Metrics**: Gunakan berbagai metrik evaluasi\n",
        "- **Cross-Validation**: Gunakan cross-validation untuk validasi\n",
        "- **Residual Analysis**: Analisis residual untuk diagnosis\n",
        "- **Outlier Detection**: Deteksi dan analisis outlier\n",
        "- **Model Stability**: Periksa stabilitas model\n",
        "\n",
        "#### 9.1.5 Interpretation\n",
        "- **Context**: Interpretasi dalam konteks penelitian\n",
        "- **Limitations**: Diskusikan keterbatasan model\n",
        "- **Implications**: Jelaskan implikasi praktis\n",
        "- **Recommendations**: Berikan rekomendasi tindakan\n",
        "- **Uncertainty**: Diskusikan ketidakpastian hasil\n",
        "\n",
        "### 9.2 Troubleshooting Common Problems\n",
        "\n",
        "#### 9.2.1 Data Problems\n",
        "\n",
        "##### Missing Values\n",
        "- **Problem**: Data tidak lengkap untuk beberapa variabel\n",
        "- **Symptoms**: Error saat fitting model, hasil yang tidak konsisten\n",
        "- **Solutions**:\n",
        "  - **Listwise Deletion**: Hapus observasi dengan missing values\n",
        "  - **Pairwise Deletion**: Gunakan data yang tersedia\n",
        "  - **Imputation**: Isi missing values dengan nilai yang masuk akal\n",
        "  - **Multiple Imputation**: Gunakan multiple imputation untuk ketidakpastian\n",
        "\n",
        "##### Outliers\n",
        "- **Problem**: Data ekstrem yang mempengaruhi model\n",
        "- **Symptoms**: Residual yang besar, model yang tidak stabil\n",
        "- **Solutions**:\n",
        "  - **Identify**: Gunakan box plot, scatter plot, atau statistical tests\n",
        "  - **Investigate**: Periksa apakah outlier adalah error atau data valid\n",
        "  - **Handle**: Hapus, transform, atau gunakan robust methods\n",
        "  - **Document**: Catat keputusan dan alasan\n",
        "\n",
        "##### Non-normal Distribution\n",
        "- **Problem**: Data tidak berdistribusi normal\n",
        "- **Symptoms**: Residual tidak normal, model tidak valid\n",
        "- **Solutions**:\n",
        "  - **Transform**: Gunakan log, square root, atau Box-Cox transformation\n",
        "  - **Robust Methods**: Gunakan metode yang robust terhadap non-normality\n",
        "  - **Non-parametric**: Gunakan metode non-parametrik\n",
        "  - **Bootstrap**: Gunakan bootstrap untuk inference\n",
        "\n",
        "#### 9.2.2 Model Problems\n",
        "\n",
        "##### Multicollinearity\n",
        "- **Problem**: Variabel independen berkorelasi tinggi\n",
        "- **Symptoms**: VIF tinggi, koefisien tidak stabil, standard error besar\n",
        "- **Solutions**:\n",
        "  - **Remove Variables**: Hapus variabel yang redundan\n",
        "  - **Combine Variables**: Gabungkan variabel yang berkorelasi\n",
        "  - **Regularization**: Gunakan Ridge, Lasso, atau Elastic Net\n",
        "  - **Principal Components**: Gunakan PCA untuk mengurangi dimensi\n",
        "\n",
        "##### Heteroscedasticity\n",
        "- **Problem**: Varians residual tidak konstan\n",
        "- **Symptoms**: Residual plot menunjukkan pola, Breusch-Pagan test signifikan\n",
        "- **Solutions**:\n",
        "  - **Transform**: Transform variabel dependen atau independen\n",
        "  - **Weighted Regression**: Gunakan weighted least squares\n",
        "  - **Robust Standard Errors**: Gunakan robust standard errors\n",
        "  - **Heteroscedasticity-consistent**: Gunakan HC standard errors\n",
        "\n",
        "##### Autocorrelation\n",
        "- **Problem**: Residual berkorelasi dengan residual lain\n",
        "- **Symptoms**: Durbin-Watson test signifikan, residual plot menunjukkan pola\n",
        "- **Solutions**:\n",
        "  - **Time Series Methods**: Gunakan metode time series\n",
        "  - **Lagged Variables**: Tambahkan variabel lag\n",
        "  - **ARIMA**: Gunakan ARIMA untuk time series\n",
        "  - **Cochrane-Orcutt**: Gunakan Cochrane-Orcutt procedure\n",
        "\n",
        "##### Non-linearity\n",
        "- **Problem**: Hubungan tidak linear antara variabel\n",
        "- **Symptoms**: Residual plot menunjukkan pola non-linear\n",
        "- **Solutions**:\n",
        "  - **Polynomial Terms**: Tambahkan polynomial terms\n",
        "  - **Interaction Terms**: Tambahkan interaction terms\n",
        "  - **Spline Regression**: Gunakan spline regression\n",
        "  - **Non-linear Models**: Gunakan model non-linear\n",
        "\n",
        "#### 9.2.3 Statistical Problems\n",
        "\n",
        "##### Low R-squared\n",
        "- **Problem**: Model menjelaskan sedikit varians\n",
        "- **Symptoms**: R-squared rendah, model tidak prediktif\n",
        "- **Solutions**:\n",
        "  - **Add Variables**: Tambahkan variabel yang relevan\n",
        "  - **Transform Variables**: Transform variabel untuk meningkatkan hubungan\n",
        "  - **Interaction Terms**: Tambahkan interaction terms\n",
        "  - **Non-linear Terms**: Tambahkan non-linear terms\n",
        "\n",
        "##### Non-significant Coefficients\n",
        "- **Problem**: Koefisien tidak signifikan secara statistik\n",
        "- **Symptoms**: P-value tinggi, confidence interval lebar\n",
        "- **Solutions**:\n",
        "  - **Increase Sample Size**: Tingkatkan ukuran sample\n",
        "  - **Reduce Multicollinearity**: Kurangi multikolinearitas\n",
        "  - **Transform Variables**: Transform variabel untuk meningkatkan hubungan\n",
        "  - **Check Assumptions**: Periksa asumsi model\n",
        "\n",
        "##### Overfitting\n",
        "- **Problem**: Model terlalu kompleks, performa buruk pada data baru\n",
        "- **Symptoms**: R-squared tinggi pada training, rendah pada validation\n",
        "- **Solutions**:\n",
        "  - **Cross-validation**: Gunakan cross-validation untuk evaluasi\n",
        "  - **Regularization**: Gunakan Ridge, Lasso, atau Elastic Net\n",
        "  - **Feature Selection**: Pilih fitur yang paling penting\n",
        "  - **Simplify Model**: Sederhanakan model\n",
        "\n",
        "### 9.3 Common Mistakes\n",
        "\n",
        "#### 9.3.1 Data Mistakes\n",
        "- **Ignoring Missing Values**: Tidak menangani missing values dengan tepat\n",
        "- **Not Checking Data Quality**: Tidak memeriksa kualitas data\n",
        "- **Using Wrong Data Types**: Menggunakan tipe data yang salah\n",
        "- **Not Handling Outliers**: Tidak menangani outlier dengan tepat\n",
        "- **Not Checking Assumptions**: Tidak memeriksa asumsi model\n",
        "\n",
        "#### 9.3.2 Model Mistakes\n",
        "- **Overfitting**: Model terlalu kompleks\n",
        "- **Underfitting**: Model terlalu sederhana\n",
        "- **Ignoring Multicollinearity**: Tidak menangani multikolinearitas\n",
        "- **Not Validating Model**: Tidak memvalidasi model\n",
        "- **Not Checking Residuals**: Tidak memeriksa residual\n",
        "\n",
        "#### 9.3.3 Interpretation Mistakes\n",
        "- **Confusing Correlation with Causation**: Mengacaukan korelasi dengan kausalitas\n",
        "- **Ignoring Context**: Tidak mempertimbangkan konteks\n",
        "- **Overinterpreting Results**: Terlalu berlebihan dalam interpretasi\n",
        "- **Not Discussing Limitations**: Tidak membahas keterbatasan\n",
        "- **Not Considering Uncertainty**: Tidak mempertimbangkan ketidakpastian\n",
        "\n",
        "### 9.4 Software dan Tools\n",
        "\n",
        "#### 9.4.1 Python\n",
        "- **scikit-learn**: Machine learning library\n",
        "- **statsmodels**: Statistical models\n",
        "- **pandas**: Data manipulation\n",
        "- **numpy**: Numerical computing\n",
        "- **matplotlib/seaborn**: Visualization\n",
        "\n",
        "#### 9.4.2 R\n",
        "- **lm()**: Linear regression\n",
        "- **glm()**: Generalized linear models\n",
        "- **car**: Companion to Applied Regression\n",
        "- **MASS**: Modern Applied Statistics\n",
        "- **ggplot2**: Visualization\n",
        "\n",
        "#### 9.4.3 SPSS\n",
        "- **Linear Regression**: Built-in regression analysis\n",
        "- **Multiple Regression**: Advanced regression options\n",
        "- **Model Selection**: Stepwise, forward, backward\n",
        "- **Diagnostics**: Residual analysis, outlier detection\n",
        "\n",
        "#### 9.4.4 SAS\n",
        "- **PROC REG**: Regression analysis\n",
        "- **PROC GLM**: General linear models\n",
        "- **PROC LOGISTIC**: Logistic regression\n",
        "- **PROC MIXED**: Mixed models\n",
        "\n",
        "### 9.5 Reporting Guidelines\n",
        "\n",
        "#### 9.5.1 Model Description\n",
        "- **Variables**: Jelaskan semua variabel yang digunakan\n",
        "- **Sample Size**: Berikan ukuran sample dan power analysis\n",
        "- **Method**: Jelaskan metode yang digunakan\n",
        "- **Assumptions**: Diskusikan asumsi dan validasi\n",
        "- **Limitations**: Jelaskan keterbatasan model\n",
        "\n",
        "#### 9.5.2 Results Presentation\n",
        "- **Tables**: Gunakan tabel yang jelas dan informatif\n",
        "- **Figures**: Gunakan grafik yang mendukung interpretasi\n",
        "- **Statistics**: Berikan statistik yang relevan\n",
        "- **Effect Sizes**: Diskusikan effect sizes, bukan hanya p-values\n",
        "- **Confidence Intervals**: Berikan confidence intervals\n",
        "\n",
        "#### 9.5.3 Interpretation\n",
        "- **Context**: Interpretasi dalam konteks penelitian\n",
        "- **Practical Significance**: Diskusikan signifikansi praktis\n",
        "- **Implications**: Jelaskan implikasi untuk praktik\n",
        "- **Recommendations**: Berikan rekomendasi tindakan\n",
        "- **Future Research**: Saran untuk penelitian selanjutnya\n",
        "\n",
        "### 9.6 Analysis Checklist\n",
        "\n",
        "#### 9.6.1 Pre-analysis\n",
        "- [ ] Data quality check\n",
        "- [ ] Missing values analysis\n",
        "- [ ] Outlier detection\n",
        "- [ ] Data distribution check\n",
        "- [ ] Variable selection\n",
        "- [ ] Sample size adequacy\n",
        "\n",
        "#### 9.6.2 Analysis\n",
        "- [ ] Model fitting\n",
        "- [ ] Assumption checking\n",
        "- [ ] Multicollinearity check\n",
        "- [ ] Residual analysis\n",
        "- [ ] Outlier detection\n",
        "- [ ] Model validation\n",
        "\n",
        "#### 9.6.3 Post-analysis\n",
        "- [ ] Results interpretation\n",
        "- [ ] Effect size calculation\n",
        "- [ ] Confidence intervals\n",
        "- [ ] Model comparison\n",
        "- [ ] Sensitivity analysis\n",
        "- [ ] Reporting\n",
        "\n",
        "### 9.7 Summary\n",
        "\n",
        "Regresi multiple adalah teknik statistik yang powerful untuk analisis multivariat, tetapi memerlukan perhatian khusus pada:\n",
        "\n",
        "1. **Data Quality**: Pastikan data berkualitas tinggi\n",
        "2. **Assumptions**: Periksa dan validasi asumsi model\n",
        "3. **Multicollinearity**: Tangani multikolinearitas dengan tepat\n",
        "4. **Validation**: Validasi model dengan data independen\n",
        "5. **Interpretation**: Interpretasi yang hati-hati dan kontekstual\n",
        "6. **Reporting**: Pelaporan yang komprehensif dan transparan\n",
        "\n",
        "Dengan mengikuti best practices dan menghindari common mistakes, regresi multiple dapat memberikan insights yang valuable untuk penelitian dan pengambilan keputusan.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Kesimpulan\n",
        "\n",
        "### 10.1 Ringkasan Materi\n",
        "\n",
        "Regresi multiple adalah teknik statistik yang powerful untuk analisis multivariat yang memungkinkan kita untuk:\n",
        "\n",
        "1. **Memahami Hubungan Kompleks**: Menganalisis hubungan antara satu variabel dependen dengan beberapa variabel independen\n",
        "2. **Membuat Prediksi**: Memprediksi nilai variabel dependen berdasarkan nilai variabel independen\n",
        "3. **Mengontrol Variabel**: Mengontrol pengaruh variabel lain saat menganalisis hubungan\n",
        "4. **Mengidentifikasi Faktor Penting**: Menentukan variabel mana yang paling berpengaruh\n",
        "5. **Mengukur Efek Parsial**: Mengukur efek unik setiap variabel independen\n",
        "\n",
        "### 10.2 Konsep Kunci\n",
        "\n",
        "#### 10.2.1 Model Regresi Multiple\n",
        "- **Persamaan**: Y = β₀ + β₁X₁ + β₂X₂ + ... + βₖXₖ + ε\n",
        "- **Koefisien**: βᵢ menunjukkan perubahan Y per unit perubahan Xᵢ\n",
        "- **Intercept**: β₀ adalah nilai Y ketika semua X = 0\n",
        "- **Error**: ε adalah error term yang tidak dapat dijelaskan\n",
        "\n",
        "#### 10.2.2 Interpretasi Koefisien\n",
        "- **Partial Effect**: Efek Xᵢ pada Y dengan mengontrol variabel lain\n",
        "- **Standardized**: Koefisien yang distandarisasi untuk perbandingan\n",
        "- **Confidence Interval**: Rentang nilai yang mungkin untuk koefisien\n",
        "- **Significance**: Apakah koefisien berbeda dari nol secara statistik\n",
        "\n",
        "#### 10.2.3 Evaluasi Model\n",
        "- **R-squared**: Proporsi varians yang dijelaskan model\n",
        "- **Adjusted R-squared**: R-squared yang disesuaikan untuk jumlah variabel\n",
        "- **RMSE**: Root Mean Square Error untuk mengukur akurasi prediksi\n",
        "- **AIC/BIC**: Information criteria untuk perbandingan model\n",
        "\n",
        "#### 10.2.4 Asumsi Model\n",
        "- **Linearity**: Hubungan linear antara variabel\n",
        "- **Independence**: Observasi independen satu sama lain\n",
        "- **Homoscedasticity**: Varians error konstan\n",
        "- **Normality**: Error berdistribusi normal\n",
        "- **No Multicollinearity**: Variabel independen tidak berkorelasi tinggi\n",
        "\n",
        "### 10.3 Aplikasi Praktis\n",
        "\n",
        "Regresi multiple memiliki aplikasi yang luas di berbagai bidang:\n",
        "\n",
        "1. **Penelitian Medis**: Prediksi risiko penyakit, analisis efektivitas pengobatan\n",
        "2. **Penelitian Ekonomi**: Forecasting permintaan, analisis elastisitas harga\n",
        "3. **Penelitian Psikologi**: Prediksi perilaku, analisis efektivitas terapi\n",
        "4. **Penelitian Bisnis**: Forecasting penjualan, analisis nilai pelanggan\n",
        "5. **Penelitian Pendidikan**: Analisis prestasi siswa, efektivitas mengajar\n",
        "6. **Penelitian Teknologi**: Analisis performa sistem, user engagement\n",
        "7. **Penelitian Lingkungan**: Modeling iklim, prediksi polusi\n",
        "8. **Penelitian Sosial**: Analisis perilaku sosial, dampak kebijakan\n",
        "\n",
        "### 10.4 Best Practices\n",
        "\n",
        "#### 10.4.1 Persiapan Data\n",
        "- Pastikan data berkualitas tinggi\n",
        "- Handle missing values dengan tepat\n",
        "- Identifikasi dan handle outliers\n",
        "- Periksa distribusi data\n",
        "\n",
        "#### 10.4.2 Model Building\n",
        "- Mulai dengan model sederhana\n",
        "- Tambahkan variabel secara bertahap\n",
        "- Periksa asumsi model\n",
        "- Validasi dengan data independen\n",
        "\n",
        "#### 10.4.3 Interpretasi\n",
        "- Interpretasi dalam konteks penelitian\n",
        "- Diskusikan keterbatasan model\n",
        "- Jelaskan implikasi praktis\n",
        "- Berikan rekomendasi tindakan\n",
        "\n",
        "### 10.5 Keterbatasan\n",
        "\n",
        "#### 10.5.1 Asumsi Model\n",
        "- Model mengasumsikan hubungan linear\n",
        "- Error harus berdistribusi normal\n",
        "- Tidak ada multikolinearitas\n",
        "- Observasi harus independen\n",
        "\n",
        "#### 10.5.2 Interpretasi\n",
        "- Korelasi bukan kausalitas\n",
        "- Model hanya menjelaskan, tidak memprediksi\n",
        "- Hasil bergantung pada data yang digunakan\n",
        "- Tidak dapat menangani hubungan non-linear\n",
        "\n",
        "#### 10.5.3 Praktis\n",
        "- Memerlukan data berkualitas tinggi\n",
        "- Interpretasi bisa kompleks\n",
        "- Memerlukan pengetahuan statistik\n",
        "- Tidak selalu memberikan jawaban yang jelas\n",
        "\n",
        "### 10.6 Rekomendasi\n",
        "\n",
        "#### 10.6.1 Untuk Peneliti\n",
        "- Pahami asumsi model sebelum menggunakan\n",
        "- Validasi model dengan data independen\n",
        "- Diskusikan keterbatasan dalam laporan\n",
        "- Gunakan multiple methods untuk validasi\n",
        "\n",
        "#### 10.6.2 Untuk Praktisi\n",
        "- Pastikan data berkualitas tinggi\n",
        "- Gunakan software yang tepat\n",
        "- Interpretasi hasil dengan hati-hati\n",
        "- Konsultasi dengan ahli statistik jika perlu\n",
        "\n",
        "#### 10.6.3 Untuk Pembelajar\n",
        "- Pahami konsep dasar sebelum praktik\n",
        "- Latihan dengan data nyata\n",
        "- Pelajari berbagai metode\n",
        "- Jangan takut bertanya\n",
        "\n",
        "### 10.7 Penutup\n",
        "\n",
        "Regresi multiple adalah teknik statistik yang powerful dan versatile yang dapat memberikan insights yang valuable untuk penelitian dan pengambilan keputusan. Namun, teknik ini memerlukan pemahaman yang baik tentang asumsi, keterbatasan, dan interpretasi yang tepat.\n",
        "\n",
        "Dengan mengikuti best practices dan menghindari common mistakes, regresi multiple dapat menjadi alat yang sangat berguna untuk analisis data multivariat. Ingatlah bahwa statistik adalah alat untuk membantu pemahaman, bukan untuk menggantikan pemikiran kritis dan konteks penelitian.\n",
        "\n",
        "Selamat belajar dan semoga sukses dalam penerapan regresi multiple dalam penelitian Anda!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
